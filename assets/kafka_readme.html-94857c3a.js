import{_ as p,M as o,p as e,q as c,R as n,t as l,N as u,a1 as a}from"./framework-d81ad7e5.js";const k="/assets/1-35184cd4.png",r="/assets/2-ebe8e727.png",i="/assets/3-38135e91.png",d="/assets/4-cfe6a327.png",m="/assets/5-df819320.png",g="/assets/6-d8780876.png",f="/assets/7-81dbfdbd.png",b="/assets/8-40bb33e9.png",h="/assets/9-288d480f.png",s="/assets/10-22fe857e.png",v="/assets/12-6d6593e9.png",y="/assets/13-9a9500c9.png",q="/assets/14-4c3673c9.png",_="/assets/15-83f179ff.png",w="/assets/16-208ab26b.png",S="/assets/17-410051f2.png",C="/assets/18-9093e0c5.png",x="/assets/19-d69913f6.png",P="/assets/20-ffbb6f7f.png",R="/assets/21-e723d8e4.png",E="/assets/22-a6a29740.png",I="/assets/23-7155201f.png",j="/assets/24-89babb01.png",A="/assets/25-4e98e8c9.png",L="/assets/26-9820fd91.png",T="/assets/27-6c22324b.png",O="/assets/28-975fc206.png",K="/assets/29-8b074e30.png",z="/assets/30-42e47a5b.png",N="/assets/31-323736ba.png",F="/assets/32-b3d7a9c7.png",$="/assets/33-c49649d2.png",G="/assets/34-f239c2df.png",D="/assets/35-87a45d8e.png",M="/assets/36-9db64079.png",V="/assets/37-3e4a0b7e.png",B="/assets/38-a05d8d33.png",Z="/assets/39-78352c57.png",H="/assets/40-488cd7ce.png",X="/assets/41-07912c30.png",U="/assets/42-69f8336d.png",Y="/assets/43-06e37e5f.png",Q="/assets/44-2770267f.png",W="/assets/45-c641cd49.png",J="/assets/46-070e4ad5.png",nn="/assets/47-938b1f4b.png",sn="/assets/48-e96bcdc2.png",an="/assets/49-820ce2e4.png",tn="/assets/50-7f2ef053.png",pn="/assets/51-f384b846.png",on="/assets/52-ceeed342.png",en="/assets/53-7a8aedab.png",cn="/assets/54-905698a0.png",ln="/assets/55-9174d0d9.png",un="/assets/56-fd36cb2d.png",kn="/assets/57-e8c59823.png",rn="/assets/58-688d501b.png",dn="/assets/59-7675fcb4.png",mn="/assets/60-9a605d78.png",gn="/assets/61-5cc29880.png",fn="/assets/62-a21afe81.png",bn="/assets/63-3cb3b952.png",hn="/assets/64-b6bdf83a.png",vn="/assets/65-2ee6d985.png",yn="/assets/66-3556e62e.png",qn="/assets/67-d8a832d4.png",_n="/assets/68-a4d865b8.png",wn="/assets/69-ff5d1a4f.png",Sn="/assets/70-9adbf972.png",Cn="/assets/71-601821ca.png",xn={},Pn=a('<h3 id="一、kafka概述" tabindex="-1"><a class="header-anchor" href="#一、kafka概述" aria-hidden="true">#</a> 一、Kafka概述</h3><h4 id="_1-1-定义" tabindex="-1"><a class="header-anchor" href="#_1-1-定义" aria-hidden="true">#</a> 1.1 定义</h4><p><strong>Kafka传统定义</strong>： Kafka是一个分布式的基于<strong>发布/订阅模式</strong>的消息队列（Message Queue），主要应用于大数据实时处理领域。</p><p><strong>发布/订阅</strong>：消息的发布者不会将消息直接发布给特定的订阅者，而是将发布的消息分为不同的类别，订阅者只接收感兴趣的消息。</p><p><strong>Kafka最新定义</strong>：Kafka是一个开源的分布式事件流平台（Event Streaming Platform），被数千家公司用于高性能的数据管道、流分析、数据集成和关键任务应用。 <img src="'+k+'" alt="3aac"><img src="'+r+'" alt="3ccd"></p><blockquote></blockquote><h4 id="_1-2-消息队列" tabindex="-1"><a class="header-anchor" href="#_1-2-消息队列" aria-hidden="true">#</a> 1.2 消息队列</h4><p>目前企业中比较常见的消息队列产品主要有Kafka、ActiveMQ、RabbitMQ、RocketMQ等。</p><p>在大数据场景主要采用Kafka作为消息队列。在JavaEE开发中主要采用ActiveMQ、RabbitMQ、RocketMQ。</p><h5 id="_1-2-1-传统消息队列的应用场景" tabindex="-1"><a class="header-anchor" href="#_1-2-1-传统消息队列的应用场景" aria-hidden="true">#</a> 1.2.1 传统消息队列的应用场景</h5><p>传统的消息队列的主要应用场景包括**：缓存/消峰、解耦<strong>和</strong>异步通信**。</p><p><strong>缓冲/消峰</strong>： 有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。</p><p><img src="'+i+'" alt="3"></p><p><strong>解耦</strong>：允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p><p><img src="'+d+'" alt="4"></p><p><strong>异步通信</strong>：允许用户把一个消息放入队列，但并不立即处理它，然后再需要的时候再去处理它们。</p><p><img src="'+m+'" alt="5"></p><h5 id="_1-2-2-消息队列的两种模式" tabindex="-1"><a class="header-anchor" href="#_1-2-2-消息队列的两种模式" aria-hidden="true">#</a> 1.2.2 消息队列的两种模式</h5><p><strong>1、点对点模式</strong></p><ul><li>消费者主动拉去数据，消息收到后清除消息</li></ul><p><img src="'+g+'" alt="6"></p><p><strong>2、发布/订阅模式</strong></p><ul><li>可以有多个topic主题(浏览，点赞，收藏，评论等)</li><li>消费者消费数据之后，不删除数据</li><li>每个消费者互相独立，都可以消费到数据</li></ul><p><img src="'+f+'" alt="7"></p><h4 id="_1-3-kafka基础架构" tabindex="-1"><a class="header-anchor" href="#_1-3-kafka基础架构" aria-hidden="true">#</a> 1.3 Kafka基础架构</h4><p>1、为方便扩展，并提高吞吐量，一个topic分为多个partition</p><p>2、配合分区的设计，提出消费者组的概念，组内每个消费者并行消费</p><p>3、为提高可用性，为每个partition增加若干副本，类似NameNode HA</p><p>4、ZK中记录谁是leader，Kafka2.8.0 以后也可以配置不采用ZK</p><p><img src="'+b+`" alt="8"></p><ul><li><p><strong>Producer</strong>：消息生产者，就是向Kafka broker 发消息的客户端。</p></li><li><p><strong>Consumer</strong>：消息消费者，向Kafka broker 取消息的客户端。</p></li><li><p><strong>Consumer Group（CG）</strong>：消费者组，由多个consumer组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p></li><li><p><strong>Broker</strong>：一台Kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。</p></li><li><p><strong>Topic</strong>： 可以理解为一个队列，生产者和消费者面向的都是一个topic。</p></li><li><p><strong>Partition</strong>： 为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。</p></li><li><p><strong>Replica</strong>：副本。一个topic的每个分区都有若干个副本，一个Leader和若干个Follower。</p></li><li><p><strong>Leader</strong>：每个分区多个副本的 &quot;主&quot;，生产者发送数据的对象，以及消费者消费数据的对象都是Leader。</p></li><li><p><strong>Follower</strong>：每个分区多个副本中的 &quot;从&quot;，实时从 Leader 中同步数据，保持和 Leader 数据的同步。Leader 发生故障时，某个Follower会成为新的 Leader。</p></li></ul><h3 id="二、kafka快速入门" tabindex="-1"><a class="header-anchor" href="#二、kafka快速入门" aria-hidden="true">#</a> 二、Kafka快速入门</h3><h4 id="_2-1-安装部署" tabindex="-1"><a class="header-anchor" href="#_2-1-安装部署" aria-hidden="true">#</a> 2.1 安装部署</h4><h5 id="_2-1-1-集群规划" tabindex="-1"><a class="header-anchor" href="#_2-1-1-集群规划" aria-hidden="true">#</a> 2.1.1 集群规划</h5><table><thead><tr><th>Hadoop102</th><th>Hadoop103</th><th>Hadoop104</th></tr></thead><tbody><tr><td>zk</td><td>zk</td><td>zk</td></tr><tr><td>kafka</td><td>kafka</td><td>kafka</td></tr></tbody></table><h5 id="_2-1-2-集群部署" tabindex="-1"><a class="header-anchor" href="#_2-1-2-集群部署" aria-hidden="true">#</a> 2.1.2 集群部署</h5><p>1、官方下载地址：http://kafka.apache.org/downloads.html</p><p>2、解压安装包</p><div class="language-tex" data-ext="tex"><pre class="language-tex"><code><span class="token punctuation">[</span>yooome@192 local <span class="token comment">% sudo tar -zxvf kafka_2.13-3.1.0.tgz </span>
</code></pre></div><p>3、修改解压后的文件名称</p><div class="language-basic" data-ext="basic"><pre class="language-basic"><code>[yooome@<span class="token number">192</span> local % sudo mv kafka_2.<span class="token number">13</span><span class="token operator">-</span><span class="token number">3.1</span><span class="token number">.0</span> kafka
</code></pre></div><p>4、进入到/usr/local/kafka目录，修改配置文件</p><div class="language-basic" data-ext="basic"><pre class="language-basic"><code>yooome@<span class="token number">192</span> kafka % cd config 
yooome@<span class="token number">192</span> config % vim server.properties 
</code></pre></div><p>输入一下内容：</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token comment">#broker 的全局唯一编号，不能重复，只能是数字。</span>
<span class="token assign-left variable">broker.id</span><span class="token operator">=</span><span class="token number">0</span>
<span class="token comment">#处理网络请求的线程数量</span>
<span class="token assign-left variable">num.network.threads</span><span class="token operator">=</span><span class="token number">3</span>
<span class="token comment">#用来处理磁盘 IO 的线程数量</span>
<span class="token assign-left variable">num.io.threads</span><span class="token operator">=</span><span class="token number">8</span>
<span class="token comment">#发送套接字的缓冲区大小</span>
<span class="token assign-left variable">socket.send.buffer.bytes</span><span class="token operator">=</span><span class="token number">102400</span>
<span class="token comment">#接收套接字的缓冲区大小</span>
<span class="token assign-left variable">socket.receive.buffer.bytes</span><span class="token operator">=</span><span class="token number">102400</span>
<span class="token comment">#请求套接字的缓冲区大小</span>
<span class="token assign-left variable">socket.request.max.bytes</span><span class="token operator">=</span><span class="token number">104857600</span>
<span class="token comment">#kafka 运行日志(数据)存放的路径，路径不需要提前创建，kafka 自动帮你创建，可以</span>
配置多个磁盘路径，路径与路径之间可以用<span class="token string">&quot;，&quot;</span>分隔
<span class="token assign-left variable">log.dirs</span><span class="token operator">=</span>/opt/module/kafka/datas
<span class="token comment">#topic 在当前 broker 上的分区个数</span>
<span class="token assign-left variable">num.partitions</span><span class="token operator">=</span><span class="token number">1</span>
<span class="token comment">#用来恢复和清理 data 下数据的线程数量</span>
<span class="token assign-left variable">num.recovery.threads.per.data.dir</span><span class="token operator">=</span><span class="token number">1</span>
<span class="token comment"># 每个 topic 创建时的副本数，默认时 1 个副本</span>
<span class="token assign-left variable">offsets.topic.replication.factor</span><span class="token operator">=</span><span class="token number">1</span>
<span class="token comment">#segment 文件保留的最长时间，超时将被删除</span>
<span class="token assign-left variable">log.retention.hours</span><span class="token operator">=</span><span class="token number">168</span>
<span class="token comment">#每个 segment 文件的大小，默认最大 1G</span>
<span class="token assign-left variable">log.segment.bytes</span><span class="token operator">=</span><span class="token number">1073741824</span>
<span class="token comment"># 检查过期数据的时间，默认 5 分钟检查一次是否数据过期</span>
<span class="token assign-left variable">log.retention.check.interval.ms</span><span class="token operator">=</span><span class="token number">300000</span>
<span class="token comment">#配置连接 Zookeeper 集群地址（在 zk 根目录下创建/kafka，方便管理）</span>
<span class="token assign-left variable">zookeeper.connect</span><span class="token operator">=</span>hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka
</code></pre></div><p>5、分发安装包</p><div class="language-ba" data-ext="ba"><pre class="language-ba"><code>[yooome@hadoop102 module]$ xsync kafka/
</code></pre></div><p>6、分别在hadoop103和hadoop104 上修改配置文件/opt/module/kafka/config/server.properties中的 broker.id=1、broker.id=2</p><p><strong>注</strong>：broker.id 不得重复，整个集群中唯一</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop103 module<span class="token punctuation">]</span>$ <span class="token function">vim</span> kafka/config/server.properties
修改:
<span class="token comment"># The id of the broker. This must be set to a unique integer for each broker.</span>
<span class="token assign-left variable">broker.id</span><span class="token operator">=</span><span class="token number">1</span>
<span class="token punctuation">[</span>atguigu@hadoop104 module<span class="token punctuation">]</span>$ <span class="token function">vim</span> kafka/config/server.properties
修改:
<span class="token comment"># The id of the broker. This must be set to a unique integer for each broker.</span>
<span class="token assign-left variable">broker.id</span><span class="token operator">=</span><span class="token number">2</span>
</code></pre></div><p>7、配置环境变量</p><p>（1）在/etc/profile.d/my_env.sh 文件中增加 kafka 环境变量配置</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">vim</span> /etc/profile.d/my_env.sh
增加如下内容：
<span class="token comment">#KAFKA_HOME</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">KAFKA_HOME</span><span class="token operator">=</span>/opt/module/kafka
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$KAFKA_HOME</span>/bin
</code></pre></div><p>（2）刷新一下环境变量。</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 module<span class="token punctuation">]</span>$ <span class="token builtin class-name">source</span> /etc/profile
</code></pre></div><p>（3）分发环境变量文件到其他节点，并 source。</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">sudo</span> /home/atguigu/bin/xsync /etc/profile.d/my_env.sh
<span class="token punctuation">[</span>atguigu@hadoop103 module<span class="token punctuation">]</span>$ <span class="token builtin class-name">source</span> /etc/profile
<span class="token punctuation">[</span>atguigu@hadoop104 module<span class="token punctuation">]</span>$ <span class="token builtin class-name">source</span> /etc/profile
</code></pre></div><p>8、启动集群</p><p>（1）先启动 Zookeeper 集群，然后启动 Kafka。</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ zk.sh start
</code></pre></div><p>（2）依次在 hadoop102、hadoop103、hadoop104 节点上启动 Kafka。</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-server-start.sh <span class="token parameter variable">-daemon</span>
config/server.properties
<span class="token punctuation">[</span>atguigu@hadoop103 kafka<span class="token punctuation">]</span>$ bin/kafka-server-start.sh <span class="token parameter variable">-daemon</span>
config/server.properties
<span class="token punctuation">[</span>atguigu@hadoop104 kafka<span class="token punctuation">]</span>$ bin/kafka-server-start.sh <span class="token parameter variable">-daemon</span>
config/server.properties
</code></pre></div><p><strong>注意：配置文件的路径要能够到 server.properties。</strong></p><p>9、关闭集群</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-server-stop.sh 
<span class="token punctuation">[</span>atguigu@hadoop103 kafka<span class="token punctuation">]</span>$ bin/kafka-server-stop.sh 
<span class="token punctuation">[</span>atguigu@hadoop104 kafka<span class="token punctuation">]</span>$ bin/kafka-server-stop.sh
</code></pre></div><h5 id="_2-1-3-集群启停脚本" tabindex="-1"><a class="header-anchor" href="#_2-1-3-集群启停脚本" aria-hidden="true">#</a> 2.1.3 集群启停脚本</h5><p>1）在/home/atguigu/bin 目录下创建文件 kf.sh 脚本文件</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">vim</span> kf.sh
</code></pre></div><p>脚本如下：</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token shebang important">#! /bin/bash</span>
<span class="token keyword">case</span> <span class="token variable">$1</span> <span class="token keyword">in</span>
<span class="token string">&quot;start&quot;</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
	<span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> hadoop102 hadoop103 hadoop104
	<span class="token keyword">do</span>
		<span class="token builtin class-name">echo</span> <span class="token string">&quot; --------启动 <span class="token variable">$i</span> Kafka-------&quot;</span>
		<span class="token function">ssh</span> <span class="token variable">$i</span> <span class="token string">&quot;/opt/module/kafka/bin/kafka-server-start.sh -
	daemon /opt/module/kafka/config/server.properties&quot;</span>
	<span class="token keyword">done</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token punctuation">;</span>
<span class="token string">&quot;stop&quot;</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
	<span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> hadoop102 hadoop103 hadoop104
	<span class="token keyword">do</span>
		<span class="token builtin class-name">echo</span> <span class="token string">&quot; --------停止 <span class="token variable">$i</span> Kafka-------&quot;</span>
		<span class="token function">ssh</span> <span class="token variable">$i</span> <span class="token string">&quot;/opt/module/kafka/bin/kafka-server-stop.sh &quot;</span>
	<span class="token keyword">done</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token punctuation">;</span>
<span class="token keyword">esac</span>
</code></pre></div><p>2）添加执行权限</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> +x kf.sh
</code></pre></div><p>3）启动集群命令</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 ~<span class="token punctuation">]</span>$ kf.sh start
</code></pre></div><p>4）停止集群命令</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 ~<span class="token punctuation">]</span>$ kf.sh stop
</code></pre></div><p><strong>注意</strong>：停止 Kafka 集群时，一定要等 Kafka 所有节点进程全部停止后再停止 Zookeeper集群。因为 Zookeeper 集群当中记录着 Kafka 集群相关信息，Zookeeper 集群一旦先停止，Kafka 集群就没有办法再获取停止进程的信息，只能手动杀死 Kafka 进程了。</p><p>待续。。。。。。</p><h4 id="_2-2-kafka命令行操作" tabindex="-1"><a class="header-anchor" href="#_2-2-kafka命令行操作" aria-hidden="true">#</a> 2.2 Kafka命令行操作</h4><h5 id="_2-2-1-kafka基础架构" tabindex="-1"><a class="header-anchor" href="#_2-2-1-kafka基础架构" aria-hidden="true">#</a> 2.2.1 Kafka基础架构</h5><p><img src="`+h+`" alt="9"></p><h5 id="_2-2-2-主题命令行操作" tabindex="-1"><a class="header-anchor" href="#_2-2-2-主题命令行操作" aria-hidden="true">#</a> 2.2.2 主题命令行操作</h5><p>1、查看操作主题命令参数</p><div class="language-basic" data-ext="basic"><pre class="language-basic"><code>yooome@<span class="token number">192</span> kafka % .<span class="token operator">/</span>bin<span class="token operator">/</span>kafka<span class="token operator">-</span>topics.sh 
</code></pre></div><table><thead><tr><th style="text-align:left;">参数</th><th style="text-align:left;">描述</th></tr></thead><tbody><tr><td style="text-align:left;">--bootstrap-server &lt;String: server toconnect to&gt;</td><td style="text-align:left;">连接的 Kafka Broker 主机名称和端口号。</td></tr><tr><td style="text-align:left;">--topic &lt;String: topic&gt;</td><td style="text-align:left;">操作的 topic 名称。</td></tr><tr><td style="text-align:left;">--create</td><td style="text-align:left;">创建主题</td></tr><tr><td style="text-align:left;">--delete</td><td style="text-align:left;">删除主题</td></tr><tr><td style="text-align:left;">--alter</td><td style="text-align:left;">修改主题</td></tr><tr><td style="text-align:left;">--list</td><td style="text-align:left;">查看所有主题</td></tr><tr><td style="text-align:left;">--describe</td><td style="text-align:left;">查看主题详细描述</td></tr><tr><td style="text-align:left;">--partitions &lt;Integer: # of partitions&gt;</td><td style="text-align:left;">设置分区数。</td></tr><tr><td style="text-align:left;">--replication-factor&lt;Integer: replication factor&gt;</td><td style="text-align:left;">设置分区副本。</td></tr><tr><td style="text-align:left;">--config &lt;String: name=value&gt;</td><td style="text-align:left;">更新系统默认的配置。</td></tr></tbody></table><p>2、查看当前服务器中的所有topic</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-topics.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--list</span>
</code></pre></div><p>3、创建 <code>first topic</code></p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-topics.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--create</span> <span class="token parameter variable">--partitions</span> <span class="token number">1</span> --replication-factor <span class="token number">1</span> <span class="token parameter variable">--topic</span> first
</code></pre></div><ul><li>选项说明： <ol><li>--topic 定义 topic 名</li><li>--replication-factor 定义副本数</li><li>--partitions 定义分区数</li></ol></li></ul><p>4、查看 <code>first</code> 主题的详情</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-topics.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> first <span class="token parameter variable">--describe</span>
</code></pre></div><p>5、修改分区数（注意：分区数只能增加，不能减少）</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-topics.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--alter</span> <span class="token parameter variable">--topic</span> first <span class="token parameter variable">--partitions</span> <span class="token number">3</span>
</code></pre></div><p>6、查看结果：</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-topics.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> first <span class="token parameter variable">--describe</span> 
Topic: first	TopicId: _Pjhmn1NTr6ufGufcnsw5A	PartitionCount: <span class="token number">3</span>	ReplicationFactor: <span class="token number">1</span>	Configs: <span class="token assign-left variable">segment.bytes</span><span class="token operator">=</span><span class="token number">1073741824</span>
	Topic: first	Partition: <span class="token number">0</span>	Leader: <span class="token number">0</span>	Replicas: <span class="token number">0</span>	Isr: <span class="token number">0</span>
	Topic: first	Partition: <span class="token number">1</span>	Leader: <span class="token number">0</span>	Replicas: <span class="token number">0</span>	Isr: <span class="token number">0</span>
	Topic: first	Partition: <span class="token number">2</span>	Leader: <span class="token number">0</span>	Replicas: <span class="token number">0</span>	Isr: <span class="token number">0</span>
</code></pre></div><p>7、删除 <code>topic </code></p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-topics.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--delete</span> <span class="token parameter variable">--topic</span> first 
</code></pre></div><h5 id="_2-2-3-生产者命令行操作" tabindex="-1"><a class="header-anchor" href="#_2-2-3-生产者命令行操作" aria-hidden="true">#</a> 2.2.3 生产者命令行操作</h5><p>1、查看操作者命令参数</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-console-producer.sh 
</code></pre></div><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>--bootstrap-server &lt;String: server toconnect to&gt;</td><td>连接的 Kafka Broker 主机名称和端口号。</td></tr><tr><td>--topic &lt;String: topic&gt;</td><td>操作的 topic 名称。</td></tr></tbody></table><p>2、发送消息</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-console-producer.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> first
<span class="token operator">&gt;</span>hello world
<span class="token operator">&gt;</span>yooome yooome
</code></pre></div><h5 id="_2-3-4-消费者命令行操作" tabindex="-1"><a class="header-anchor" href="#_2-3-4-消费者命令行操作" aria-hidden="true">#</a> 2.3.4 消费者命令行操作</h5><p>1、查看操作消费者命令参数</p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>--bootstrap-server &lt;String: server toconnect to&gt;</td><td>连接的 Kafka Broker 主机名称和端口号。</td></tr><tr><td>--topic &lt;String: topic&gt;</td><td>操作的 topic 名称。</td></tr><tr><td>--from-beginning</td><td>从头开始消费。</td></tr><tr><td>--group &lt;String: consumer group id&gt;</td><td>指定消费者组名称。</td></tr></tbody></table><p>2、消费消息</p><ul><li>消费<code>first</code> 主题中的数据</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> first
</code></pre></div><ul><li>把主题中所有的数据都读取出来（包括历史数据）。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning <span class="token parameter variable">--topic</span> first
</code></pre></div><h3 id="三、kafka生产者" tabindex="-1"><a class="header-anchor" href="#三、kafka生产者" aria-hidden="true">#</a> 三、Kafka生产者</h3><h4 id="_3-1-生产者消息发送流程" tabindex="-1"><a class="header-anchor" href="#_3-1-生产者消息发送流程" aria-hidden="true">#</a> 3.1 生产者消息发送流程</h4><h5 id="_3-1-1-发送原理" tabindex="-1"><a class="header-anchor" href="#_3-1-1-发送原理" aria-hidden="true">#</a> 3.1.1 发送原理</h5><p>在消息发送的过程中，涉及到了两个线程 --- main 线程和Sender线程。在main线程中创建了一个双端队列 RecordAccumulator。main线程将消息发送给ResordAccumlator，Sender线程不断从 RecordAccumulator 中拉去消息发送到 Kafka Broker</p><p><img src="`+s+'" alt="10"></p><h5 id="_3-1-2-生产者重要参数列表" tabindex="-1"><a class="header-anchor" href="#_3-1-2-生产者重要参数列表" aria-hidden="true">#</a> 3.1.2 生产者重要参数列表</h5><table><thead><tr><th>参数名称</th><th>描述</th></tr></thead><tbody><tr><td>bootstrap.servers</td><td>生产者连接集群所需的 broker 地 址 清 单 。 例 如hadoop102:9092,hadoop103:9092,hadoop104:9092，可以设置 1 个或者多个，中间用逗号隔开。注意这里并非需要所有的 broker 地址，因为生产者从给定的 broker里查找到其他 broker 信息。</td></tr><tr><td>key.serializer 和 value.serializer</td><td>指定发送消息的 key 和 value 的序列化类型。一定要写全类名。</td></tr><tr><td>buffer.memory</td><td>RecordAccumulator 缓冲区总大小，默认 32m。</td></tr><tr><td>batch.size</td><td>缓冲区一批数据最大值，默认 16k。适当增加该值，可以提高吞吐量，但是如果该值设置太大，会导致数据传输延迟增加。</td></tr><tr><td>linger.ms</td><td>如果数据迟迟未达到 batch.size，sender 等待 linger.time之后就会发送数据。单位 ms，默认值是 0ms，表示没有延迟。生产环境建议该值大小为 5-100ms 之间。</td></tr><tr><td>acks</td><td>0：生产者发送过来的数据，不需要等数据落盘应答。1：生产者发送过来的数据，Leader 收到数据后应答。-1（all）：生产者发送过来的数据，Leader+和 isr 队列里面的所有节点收齐数据后应答。默认值是-1，-1 和all 是等价的。</td></tr><tr><td>max.in.flight.requests.per.connection</td><td>允许最多没有返回 ack 的次数，默认为 5，开启幂等性要保证该值是 1-5 的数字。</td></tr><tr><td>retries</td><td>当消息发送出现错误的时候，系统会重发消息。retries表示重试次数。默认是 int 最大值，2147483647。如果设置了重试，还想保证消息的有序性，需要设置MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION=1否则在重试此失败消息的时候，其他的消息可能发送成功了。</td></tr><tr><td>retry.backoff.ms</td><td>两次重试之间的时间间隔，默认是 100ms。</td></tr><tr><td>enable.idempotence</td><td>是否开启幂等性，默认 true，开启幂等性。</td></tr><tr><td>compression.type</td><td>生产者发送的所有数据的压缩方式。默认是 none，也就是不压缩。支持压缩类型：none、gzip、snappy、lz4 和 zstd。</td></tr></tbody></table><h4 id="_3-2-异步发送api" tabindex="-1"><a class="header-anchor" href="#_3-2-异步发送api" aria-hidden="true">#</a> 3.2 异步发送API</h4><h5 id="_3-2-1-普通异步发送" tabindex="-1"><a class="header-anchor" href="#_3-2-1-普通异步发送" aria-hidden="true">#</a> 3.2.1 普通异步发送</h5><p>1、需求：创建Kafka生产者，采用异步的方式发送到Kafka Broker。</p><ul><li><strong>异步发送流程</strong></li></ul><p><img src="'+s+`" alt="10"></p><p>2、代码编程</p><ul><li>创建工程kafka</li><li>导入依赖</li></ul><div class="language-xml" data-ext="xml"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.kafka<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>kafka-clients<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><ul><li>创建包名：com.yooome.kafka.producer</li></ul><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">KafkaProducer</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">ProducerConfig</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">ProducerRecord</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomProducer</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建kafka生产者配置对象</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// key,value 序列化（必须）：key.serializer，value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3. 创建 kafka 生产者对象</span>
        <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaProducer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 4. 调用 send 方法,发送消息</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            kafkaProducer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;yooome&quot;</span> <span class="token operator">+</span> i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token comment">// 5. 关闭资源</span>
        kafkaProducer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><ul><li>测试 <ol><li>在 hadoop102 上开启 Kafka 消费者。</li></ol></li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> first
</code></pre></div><p>​ 2. 在 IDEA 中执行代码，观察 hadoop102 控制台中是否接收到消息。</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> first
yooome0
yooome1
yooome2
yooome3
yooome4
</code></pre></div><h5 id="_3-2-2-带回调函数的异步发送" tabindex="-1"><a class="header-anchor" href="#_3-2-2-带回调函数的异步发送" aria-hidden="true">#</a> 3.2.2 带回调函数的异步发送</h5><p>回调函数会在producer收到ack时调用，为异步调用，该方法有两个参数，分别是元数据信息(RecordMetadata)和异常信息(Exception)，如果Exception为null，说明消息发送成功，如果Exception不为null，说明消息发送失败。</p><p><strong>带回调函数的异步发送</strong></p><p><img src="`+s+`" alt="10"></p><p>【注意:】消息发送失败会自动重试，不需要我们在回调函数中手动重试。</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token operator">*</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringSerializer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomProducerCallback</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建Kafka生产者的配置对象</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 给kafka配置对象添加配置信息</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3. key 序列化 key.serializer，value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 4. value 序列化 value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 5. 创建kafka生产者对象</span>
        <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaProducer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            kafkaProducer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;yooome &quot;</span> <span class="token operator">+</span> i<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Callback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token comment">// 该方法在Producer 收到 ack 时调用，为异步调用</span>
                <span class="token annotation punctuation">@Override</span>
                <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onCompletion</span><span class="token punctuation">(</span><span class="token class-name">RecordMetadata</span> recordMetadata<span class="token punctuation">,</span> <span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                    <span class="token keyword">if</span> <span class="token punctuation">(</span>e <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                        <span class="token comment">// 没有异常，输出信息到控制台</span>
                        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot; 主题：&quot;</span> <span class="token operator">+</span> recordMetadata<span class="token punctuation">.</span><span class="token function">topic</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot; -&gt; &quot;</span> <span class="token operator">+</span> <span class="token string">&quot; 分区 &quot;</span> <span class="token operator">+</span> recordMetadata<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>
                        e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">}</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">// 延迟一会会看到数据发往不同分区</span>
            <span class="token comment">//Thread.sleep(2);</span>
        <span class="token punctuation">}</span>
        <span class="token comment">// 5. 关闭资源</span>
        kafkaProducer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><ul><li>测试： <ol><li>在在 hadoop102 上开启 Kafka 消费者。</li></ol></li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> first
</code></pre></div><pre><code>	 2. 在 IDEA 中执行代码，观察 hadoop102 控制台中是否接收到消息 
</code></pre><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> first
yooome <span class="token number">0</span>
yooome <span class="token number">1</span>
yooome <span class="token number">2</span>
yooome <span class="token number">3</span>
yooome <span class="token number">4</span>
</code></pre></div><ol start="3"><li>在 IDEA 控制台观察回调信息(注意：本up主，只启用了一台kafka，故各位根据自己的集群数而定)</li></ol><p><img src="`+v+'" alt="12"></p><h4 id="_3-3-同步发送api" tabindex="-1"><a class="header-anchor" href="#_3-3-同步发送api" aria-hidden="true">#</a> 3.3 同步发送API</h4><p><img src="'+s+`" alt="10"></p><p>只需要在异步发送的基础上，在调用一下 get() 方法即可。</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token operator">*</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringSerializer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>concurrent<span class="token punctuation">.</span></span><span class="token class-name">ExecutionException</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomProducerCallback</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">InterruptedException</span><span class="token punctuation">,</span> <span class="token class-name">ExecutionException</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建Kafka生产者的配置对象</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 给kafka配置对象添加配置信息</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3. key 序列化 key.serializer，value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 4. value 序列化 value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 5. 创建kafka生产者对象</span>
        <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaProducer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token comment">//异步发送</span>
            <span class="token comment">// kafkaProducer.send(new ProducerRecord&lt;&gt;(&quot;first&quot;,&quot;kafka&quot; + i));</span>
            <span class="token comment">// 6. 同步发送</span>
            kafkaProducer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;kafka&quot;</span> <span class="token operator">+</span> i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token comment">// 7. 关闭资源</span>
        kafkaProducer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><p><strong>测试</strong>：</p><ol><li>在在 hadoop102 上开启 Kafka 消费者。</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> first
</code></pre></div><pre><code>	 2. 在 IDEA 中执行代码，观察 hadoop102 控制台中是否接收到消息 
</code></pre><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> first
kafka0
kafka1
kafka2
kafka3
kafka4
</code></pre></div><h4 id="_3-4-生产者分区" tabindex="-1"><a class="header-anchor" href="#_3-4-生产者分区" aria-hidden="true">#</a> 3.4 生产者分区</h4><h5 id="_3-4-1-分区好处" tabindex="-1"><a class="header-anchor" href="#_3-4-1-分区好处" aria-hidden="true">#</a> 3.4.1 分区好处</h5><ol><li><p><strong>便于合理使用存储资源</strong>，每个Partition在一个Broker上存储，可以把海量的数据按照分区切割成一块一块数据存储在多台Broker上。合理控制分区的任务，可以实现<strong>负载均衡</strong>的效果。</p></li><li><p><strong>提高并行度</strong>，生产者可以以分区为单位<strong>发送数据</strong>；消费者可以以分区为单位进行 <strong>消费数据</strong>。</p></li></ol><p><img src="`+y+`" alt="13"></p><h5 id="_3-4-2-生产者发送消息的分区策略" tabindex="-1"><a class="header-anchor" href="#_3-4-2-生产者发送消息的分区策略" aria-hidden="true">#</a> 3.4.2 生产者发送消息的分区策略</h5><ol><li><p><strong>默认的分区器DefaultPartitioner</strong></p><p>在IDEA中ctrl + n，全局查找 DefaultPartitioner</p></li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">DefaultPartitioner</span> <span class="token keyword">implements</span> <span class="token class-name">Partitioner</span> <span class="token punctuation">{</span>
   <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>
</code></pre></div><ol start="2"><li><strong>Kafka原则</strong></li></ol><p>ProducerRecord类，在类中可以看到如下构造方法：</p><p><img src="`+q+`" alt="14"></p><ol><li>指明partition的情况下，直接将指明的值作为partition值；例如：partition=0，所有数据写入分区0。</li><li>没有指明 partition 值但有key的情况下，将key的hash值与topic的partition数进行取余得到partition值；例如：key1的hash值=5，key2的hash值=6，topic的partition数=2，那么key1对应的value1写入 1 号分区，key2对应的 value2 写入 0 号分区。</li><li>既没有partition值又没有key值的情况下，Kafka采用 Sticky Partition（粘性分区器），会随机选择一个分区，并尽可能一直使用该分区，待该分区的 batch 已满或者已完成，Kafka在随机一个分区进行使用（和上一次的分区不同）。例如：第一次随机选择0号分区，等0号分区当前批次满了（默认16K）或者；linger.ms设置的时间到，Kafka在随机一个分区进行使用（如果还是0会继续随机）。</li></ol><p>【案例一】</p><p>将数据发往指定partition的情况下，例如，将所有数据发往分区 0【注意：本up主开启了一台kafka，只能发往分区0，你们注意自己的分区】 中。</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token operator">*</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringSerializer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>concurrent<span class="token punctuation">.</span></span><span class="token class-name">ExecutionException</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomProducerCallbackPartitions</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">InterruptedException</span><span class="token punctuation">,</span> <span class="token class-name">ExecutionException</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建Kafka生产者的配置对象</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 给kafka配置对象添加配置信息</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3. key 序列化 key.serializer，value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 4. value 序列化 value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 5. 创建kafka生产者对象</span>
        <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaProducer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token comment">//异步发送</span>
            <span class="token comment">// kafkaProducer.send(new ProducerRecord&lt;&gt;(&quot;first&quot;,&quot;kafka&quot; + i));</span>
            <span class="token comment">// 6. 同步发送</span>
            kafkaProducer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">&quot;&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;ka ka ka &quot;</span> <span class="token operator">+</span> i<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Callback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token annotation punctuation">@Override</span>
                <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onCompletion</span><span class="token punctuation">(</span><span class="token class-name">RecordMetadata</span> recordMetadata<span class="token punctuation">,</span> <span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                    <span class="token keyword">if</span> <span class="token punctuation">(</span>e <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
                        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot; 主题： &quot;</span> <span class="token operator">+</span>
                                recordMetadata<span class="token punctuation">.</span><span class="token function">topic</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot;-&gt;&quot;</span> <span class="token operator">+</span> <span class="token string">&quot;分区：&quot;</span> <span class="token operator">+</span> recordMetadata<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                        <span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>
                        e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">}</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token comment">// 7. 关闭资源</span>
        kafkaProducer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>测试：</p><ol><li>在 hadoop102 上开启 Kafka 消费者。</li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code>yooome<span class="token annotation punctuation">@192</span> kafka <span class="token operator">%</span> <span class="token punctuation">.</span>/bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>consumer<span class="token punctuation">.</span>sh <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server localhost<span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>topic first
</code></pre></div><ol start="2"><li>在IDEA中执行代码，观察 hadoop102控制台中是否接收到消息。</li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code>yooome<span class="token annotation punctuation">@192</span> kafka <span class="token operator">%</span> <span class="token punctuation">.</span>/bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>consumer<span class="token punctuation">.</span>sh <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server localhost<span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>topic first
ka ka ka <span class="token number">0</span>
ka ka ka <span class="token number">1</span>
ka ka ka <span class="token number">2</span>
ka ka ka <span class="token number">3</span>
ka ka ka <span class="token number">4</span>
</code></pre></div><ol start="3"><li>在 IDEA 控制台观察回调信息。</li></ol><p><img src="`+_+`" alt="15"></p><p>【案例二】</p><p>没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值。</p><p><strong>// 依次指定 key 值为 a,b,f ，数据 key 的 hash 值与 3 个分区求余，分别发往 1、2、0</strong></p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token operator">*</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringSerializer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>concurrent<span class="token punctuation">.</span></span><span class="token class-name">ExecutionException</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomProducerCallbackPartitions</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">InterruptedException</span><span class="token punctuation">,</span> <span class="token class-name">ExecutionException</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建Kafka生产者的配置对象</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 给kafka配置对象添加配置信息</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3. key 序列化 key.serializer，value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 4. value 序列化 value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 5. 创建kafka生产者对象</span>
        <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaProducer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token comment">//异步发送</span>
            <span class="token comment">// kafkaProducer.send(new ProducerRecord&lt;&gt;(&quot;first&quot;,&quot;kafka&quot; + i));</span>
            <span class="token comment">// 6. 同步发送</span>
            <span class="token comment">// 依次指定 key 值为 a,b,f ，数据 key 的 hash 值与 3 个分区求余，分别发往 1、2、0</span>
            kafkaProducer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">,</span>  <span class="token string">&quot;f&quot;</span><span class="token punctuation">,</span><span class="token string">&quot; fffffff &quot;</span> <span class="token operator">+</span> i<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Callback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token annotation punctuation">@Override</span>
                <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onCompletion</span><span class="token punctuation">(</span><span class="token class-name">RecordMetadata</span> recordMetadata<span class="token punctuation">,</span> <span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                    <span class="token keyword">if</span> <span class="token punctuation">(</span>e <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
                        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot; 主题： &quot;</span> <span class="token operator">+</span>
                                recordMetadata<span class="token punctuation">.</span><span class="token function">topic</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot;-&gt;&quot;</span> <span class="token operator">+</span> <span class="token string">&quot;分区：&quot;</span> <span class="token operator">+</span> recordMetadata<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                        <span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>
                        e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">}</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token comment">// 7. 关闭资源</span>
        kafkaProducer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><p>测试：</p><p>①key=&quot;a&quot;时，在控制台查看结果。</p><div class="language-java" data-ext="java"><pre class="language-java"><code>主题：first<span class="token operator">-&gt;</span>分区：<span class="token number">1</span>
主题：first<span class="token operator">-&gt;</span>分区：<span class="token number">1</span>
主题：first<span class="token operator">-&gt;</span>分区：<span class="token number">1</span>
主题：first<span class="token operator">-&gt;</span>分区：<span class="token number">1</span>
主题：first<span class="token operator">-&gt;</span>分区：<span class="token number">1</span> 
</code></pre></div><p>②key=&quot;b&quot;时，在控制台查看结果。</p><div class="language-java" data-ext="java"><pre class="language-java"><code>主题：first<span class="token operator">-&gt;</span>分区：<span class="token number">2</span>
主题：first<span class="token operator">-&gt;</span>分区：<span class="token number">2</span>
主题：first<span class="token operator">-&gt;</span>分区：<span class="token number">2</span>
主题：first<span class="token operator">-&gt;</span>分区：<span class="token number">2</span>
主题：first<span class="token operator">-&gt;</span>分区：<span class="token number">2</span> 
</code></pre></div><p>③key=&quot;f&quot;时，在控制台查看结果。</p><div class="language-java" data-ext="java"><pre class="language-java"><code>主题：first<span class="token operator">-&gt;</span>分区：<span class="token number">0</span>
主题：first<span class="token operator">-&gt;</span>分区：<span class="token number">0</span>
主题：first<span class="token operator">-&gt;</span>分区：<span class="token number">0</span>
主题：first<span class="token operator">-&gt;</span>分区：<span class="token number">0</span>
主题：first<span class="token operator">-&gt;</span>分区：<span class="token number">0</span>
</code></pre></div><h5 id="_3-4-3-自定义分区器" tabindex="-1"><a class="header-anchor" href="#_3-4-3-自定义分区器" aria-hidden="true">#</a> 3.4.3 自定义分区器</h5><p>如果研发人员可以根据企业需求，自己重新实现分区器</p><ol><li><strong>需求</strong></li></ol><p>例如我们实现一个分区器实现，发送过来的数据中如果包含 yooome，就发往 0 号分区，不包含 yooome ，就发往 1 号分区。</p><ol start="2"><li><p>实现步骤：</p><p>(1) 定义类实现 Partition 接口。</p><p>(2) 重写 partition() 方法。</p></li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">Partitioner</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span></span><span class="token class-name">Cluster</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Map</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyPartitioner</span> <span class="token keyword">implements</span> <span class="token class-name">Partitioner</span> <span class="token punctuation">{</span>
    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">partition</span><span class="token punctuation">(</span><span class="token class-name">String</span> s<span class="token punctuation">,</span> <span class="token class-name">Object</span> key<span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> bytes<span class="token punctuation">,</span> <span class="token class-name">Object</span> value<span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> bytes1<span class="token punctuation">,</span> <span class="token class-name">Cluster</span> cluster<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 获取消息</span>
        <span class="token class-name">String</span> msgValue <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 创建 partition</span>
        <span class="token keyword">int</span> partition<span class="token punctuation">;</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>msgValue<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">&quot;yooome&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            partition <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
            partition <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token keyword">return</span> partition<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>

    <span class="token punctuation">}</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token operator">?</span><span class="token punctuation">&gt;</span></span> map<span class="token punctuation">)</span> <span class="token punctuation">{</span>

    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token operator">*</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringSerializer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>concurrent<span class="token punctuation">.</span></span><span class="token class-name">ExecutionException</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomProducerCallbackPartitions</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">InterruptedException</span><span class="token punctuation">,</span> <span class="token class-name">ExecutionException</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建Kafka生产者的配置对象</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">MyPartitioner</span> myPartitioner <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">MyPartitioner</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 给kafka配置对象添加配置信息</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3. key 序列化 key.serializer，value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 4. value 序列化 value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">PARTITIONER_CLASS_CONFIG</span><span class="token punctuation">,</span> myPartitioner<span class="token punctuation">.</span><span class="token function">getClass</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 5. 创建kafka生产者对象</span>
        <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaProducer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token comment">//异步发送</span>
            <span class="token comment">// kafkaProducer.send(new ProducerRecord&lt;&gt;(&quot;first&quot;,&quot;kafka&quot; + i));</span>
            <span class="token comment">// 6. 同步发送</span>
            <span class="token comment">// 依次指定 key 值为 a,b,f ，数据 key 的 hash 值与 3 个分区求余，分别发往 1、2、0</span>
            kafkaProducer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;yooome fffffff &quot;</span> <span class="token operator">+</span> i<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Callback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token annotation punctuation">@Override</span>
                <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onCompletion</span><span class="token punctuation">(</span><span class="token class-name">RecordMetadata</span> recordMetadata<span class="token punctuation">,</span> <span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                    <span class="token keyword">if</span> <span class="token punctuation">(</span>e <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot; 主题： &quot;</span> <span class="token operator">+</span>
                                recordMetadata<span class="token punctuation">.</span><span class="token function">topic</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot;-&gt;&quot;</span> <span class="token operator">+</span> <span class="token string">&quot;分区：&quot;</span> <span class="token operator">+</span> recordMetadata<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                        <span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
                        e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">}</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token comment">// 7. 关闭资源</span>
        kafkaProducer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><p><strong>测试</strong>：</p><p>① 在 hadoop102 上开启 Kafka 消费者。</p><div class="language-java" data-ext="java"><pre class="language-java"><code>yooome<span class="token annotation punctuation">@192</span> kafka <span class="token operator">%</span> <span class="token punctuation">.</span>/bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>consumer<span class="token punctuation">.</span>sh <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server localhost<span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>topic first
</code></pre></div><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>yooome@192 kafka % ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> first
yooome fffffff <span class="token number">0</span>
yooome fffffff <span class="token number">1</span>
yooome fffffff <span class="token number">2</span>
yooome fffffff <span class="token number">3</span>
yooome fffffff <span class="token number">4</span>
</code></pre></div><p>②在 IDEA 控制台观察回调信息。</p><p><img src="`+w+'" alt="16"></p><h4 id="_3-5-生产经验-生产者如何提高吞吐量" tabindex="-1"><a class="header-anchor" href="#_3-5-生产经验-生产者如何提高吞吐量" aria-hidden="true">#</a> 3.5 生产经验----生产者如何提高吞吐量</h4><p><img src="'+S+`" alt="17"></p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token operator">*</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringSerializer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>concurrent<span class="token punctuation">.</span></span><span class="token class-name">ExecutionException</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomProducerParameters</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">ExecutionException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建Kafka生产者的配置对象</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 给kafka配置对象添加配置信息</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3. key 序列化 key.serializer，value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 4. value 序列化 value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// batch size 批次大小，默认 16k</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BATCH_SIZE_CONFIG</span><span class="token punctuation">,</span> <span class="token number">16384</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// linger.ms : 等待时间， 默认0</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">LINGER_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 缓冲区大小</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BUFFER_MEMORY_CONFIG</span><span class="token punctuation">,</span> <span class="token number">33554432</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//  compression.type：压缩，默认 none，可配置值 gzip、snappy、lz4 和 zstd</span>
        <span class="token comment">// properties.put(ProducerConfig.COMPRESSION_TYPE_CONFIG,&quot;snappy&quot;);</span>

        <span class="token comment">// 5. 创建kafka生产者对象</span>
        <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaProducer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token comment">//异步发送</span>
            <span class="token comment">// kafkaProducer.send(new ProducerRecord&lt;&gt;(&quot;first&quot;,&quot;kafka&quot; + i));</span>
            <span class="token comment">// 6. 同步发送</span>
            <span class="token comment">// 依次指定 key 值为 a,b,f ，数据 key 的 hash 值与 3 个分区求余，分别发往 1、2、0</span>
            kafkaProducer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;ProducerRecord&quot;</span> <span class="token operator">+</span> i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token comment">// 7. 关闭资源</span>
        kafkaProducer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>【注意】：compression.type：压缩，默认 none，可配置值 gzip、snappy、lz4 和 zstd</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>Mac 电脑对 compression.type 不兼容，出现报错 如下：

org.apache.spark.SparkException: Job aborted due to stage failure: Task <span class="token number">0</span> <span class="token keyword">in</span> stage <span class="token number">0.0</span> failed <span class="token number">1</span> times, <span class="token function">most</span> recent failure: Lost task <span class="token number">0.0</span> <span class="token keyword">in</span> stage <span class="token number">0.0</span> <span class="token punctuation">(</span>TID <span class="token number">0</span>, localhost, executor driver<span class="token punctuation">)</span>: org.xerial.snappy.SnappyError: <span class="token punctuation">[</span>FAILED_TO_LOAD_NATIVE_LIBRARY<span class="token punctuation">]</span> no native library is found <span class="token keyword">for</span> <span class="token assign-left variable">os.name</span><span class="token operator">=</span>Mac and <span class="token assign-left variable">os.arch</span><span class="token operator">=</span>aarch64
</code></pre></div><p><strong>测试</strong>：</p><p><strong>查看控制台是否接收到消息</strong></p><div class="language-java" data-ext="java"><pre class="language-java"><code>yooome<span class="token annotation punctuation">@192</span> kafka <span class="token operator">%</span> <span class="token punctuation">.</span>/bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>consumer<span class="token punctuation">.</span>sh <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server localhost<span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>topic first
<span class="token class-name">ProducerRecord0</span>
<span class="token class-name">ProducerRecord1</span>
<span class="token class-name">ProducerRecord2</span>
<span class="token class-name">ProducerRecord3</span>
<span class="token class-name">ProducerRecord4</span>
</code></pre></div><h4 id="_3-6-生产经验-数据可靠性" tabindex="-1"><a class="header-anchor" href="#_3-6-生产经验-数据可靠性" aria-hidden="true">#</a> 3.6 生产经验----数据可靠性</h4><h5 id="_3-6-1-回顾发送流程" tabindex="-1"><a class="header-anchor" href="#_3-6-1-回顾发送流程" aria-hidden="true">#</a> 3.6.1 回顾发送流程</h5><p><img src="`+s+'" alt="10"></p><h5 id="_3-6-2-ack应答级别" tabindex="-1"><a class="header-anchor" href="#_3-6-2-ack应答级别" aria-hidden="true">#</a> 3.6.2 ACK应答级别</h5><p><img src="'+C+'" alt="18"></p><p><img src="'+x+'" alt="19"></p><p><strong>可靠性总结</strong>：</p><ol><li>acks=0，生产者发送过来数据就不管了，可靠性差，效率高；</li><li>acks=1，生产者发送过来数据 Leader 应答，可靠性中等，效率中等；</li><li>acks=-1，生产者发送过来数据 Leader 和 ISR 队列里面所有Follwer应答，可靠性，效率低；</li></ol><p>在生产环境中，acks=0很少使用；acks=1，一般用于传输普通的日志，允许丢个别数据；acks=-1，一般用于传输和钱相关的数据，对可靠性要求比较高的场景。</p><p><strong>数据重复分析</strong>：</p><p>acks：-1（all）：生产者发送过来的数据，Leader和ISR队列里面的所有节点收齐数据后应答。</p><p><img src="'+P+`" alt="20"></p><p><strong>代码配置</strong></p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">KafkaProducer</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">ProducerConfig</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">ProducerRecord</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringSerializer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomProducerAck</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建Kafka生产者的配置对象</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 给kafka配置对象添加配置信息</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3. key 序列化 key.serializer，value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 4. value 序列化 value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 设置 acks</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">ACKS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;all&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 重试次数</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">RETRIES_CONFIG</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 5. 创建kafka生产者对象</span>
        <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaProducer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token comment">//异步发送</span>
            <span class="token comment">// kafkaProducer.send(new ProducerRecord&lt;&gt;(&quot;first&quot;,&quot;kafka&quot; + i));</span>
            <span class="token comment">// 6. 同步发送</span>
            <span class="token comment">// 依次指定 key 值为 a,b,f ，数据 key 的 hash 值与 3 个分区求余，分别发往 1、2、0</span>
            kafkaProducer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;acks acks &quot;</span> <span class="token operator">+</span> i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token comment">// 7. 关闭资源</span>
        kafkaProducer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><h4 id="_3-7-生产经验-数据去重" tabindex="-1"><a class="header-anchor" href="#_3-7-生产经验-数据去重" aria-hidden="true">#</a> 3.7 生产经验------数据去重</h4><h5 id="_3-7-1-数据传递语义" tabindex="-1"><a class="header-anchor" href="#_3-7-1-数据传递语义" aria-hidden="true">#</a> 3.7.1 数据传递语义</h5><ul><li><p>至少一次（At Least Once） = ACK 级别设置为-1 + 分区副本大于等于 2 + ISR 里应答的最小副本数量大于等于 2 ；</p></li><li><p>最多一次（At Most Once）= ACK 级别设置为 0 ；</p></li><li><p><strong>总结</strong>：</p><ol><li>At Least Once 可以保证数据不丢失，但是不能保证数据不重复；</li><li>At Most Once 可以保证数据不重复，但是不能保证数据不丢失。</li></ol></li><li><p>精确一次（Exactly Once）：对于一些非常重要的信息，比如和钱相关的数据，要求数据既不能重复也不丢失。</p><p>Kafka 0.11版本以后，引入了一项重大特性：幂等性和事务。</p></li></ul><h5 id="_3-7-2-幂等性" tabindex="-1"><a class="header-anchor" href="#_3-7-2-幂等性" aria-hidden="true">#</a> 3.7.2 幂等性</h5><ol><li><strong>幂等性原理</strong></li></ol><p><strong>幂等性</strong> 就是指 Producer 不论向 Broker 发送多少次重复数据，Broker 端都只会持久化一条，保证了不重复。</p><p><strong>精确一次（Exactly Once）</strong>= 幂等性 + 至少一次（ack=-1 + 分区副本数 &gt;= 2 + ISR 最小副本数量 &gt;= 2)。</p><p><strong>重复数据的判断标准</strong>：具有&lt;PID, Partition, SeqNumber&gt;相同主键的消息提交时，Broker只会持久化一条。其 中PID是Kafka每次重启都会分配一个新的；Partition 表示分区号；Sequence Number是单调自增的。</p><p>所以幂等性只能保证的是<strong>在单分区单会话内不重复</strong></p><p><img src="`+R+'" alt="21"></p><ol start="2"><li><p><strong>如何使用幂等性</strong></p><p>开启参数 enable.idempotence 默认为 true，false 关闭。</p></li></ol><h5 id="_3-7-3-生产者事务" tabindex="-1"><a class="header-anchor" href="#_3-7-3-生产者事务" aria-hidden="true">#</a> 3.7.3 生产者事务</h5><ol><li><strong>Kafka事务原理</strong>：</li></ol><p>【注意】说明，开启事务，必须开启幂等性</p><p><img src="'+E+`" alt="22"></p><ol start="2"><li><strong>Kafka的事务一共有如下 5 个 API</strong></li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token comment">// 1. 初始化事务</span>
<span class="token keyword">void</span> <span class="token function">initTransactions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 2. 开启事务</span>
<span class="token keyword">void</span> <span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">ProducerFencedException</span><span class="token punctuation">;</span>
<span class="token comment">// 3. 在事务内提交已经消费的偏移量(主要用于消费者)</span>
<span class="token keyword">void</span> <span class="token function">sendOffsetsToTransaction</span><span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span><span class="token class-name">OffsetAndMetadata</span><span class="token punctuation">&gt;</span></span> offsets<span class="token punctuation">,</span> <span class="token class-name">String</span> consumerGroupId<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">ProducerFencedException</span><span class="token punctuation">;</span>
<span class="token comment">// 4. 提交事务</span>
<span class="token keyword">void</span> <span class="token function">commitTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">ProducerFencedException</span><span class="token punctuation">;</span>
<span class="token comment">// 5. 放弃事务(类似于混滚事务的操作)</span>
<span class="token keyword">void</span> <span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">ProducerFencedException</span><span class="token punctuation">;</span>
</code></pre></div><ol start="3"><li>单个Producer，使用事务保证消息的仅一次发送</li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">KafkaProducer</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">ProducerConfig</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">ProducerRecord</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringSerializer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomProducerTransactions</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建Kafka生产者的配置对象</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 给kafka配置对象添加配置信息</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3. key 序列化 key.serializer，value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 4. value 序列化 value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 设置 事务 id(必须)，事务 id 任意起名</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">TRANSACTIONAL_ID_CONFIG</span><span class="token punctuation">,</span><span class="token string">&quot;transaction_id_0&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 5. 创建kafka生产者对象</span>
        <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaProducer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 初始化事务</span>
        kafkaProducer<span class="token punctuation">.</span><span class="token function">initTransactions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 开启事务</span>
        kafkaProducer<span class="token punctuation">.</span><span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">try</span> <span class="token punctuation">{</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token comment">//异步发送</span>
                <span class="token comment">// kafkaProducer.send(new ProducerRecord&lt;&gt;(&quot;first&quot;,&quot;kafka&quot; + i));</span>
                <span class="token comment">// 6. 同步发送</span>
                <span class="token comment">// 依次指定 key 值为 a,b,f ，数据 key 的 hash 值与 3 个分区求余，分别发往 1、2、0</span>
                kafkaProducer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;transaction&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
            <span class="token comment">// 提交事务</span>
            kafkaProducer<span class="token punctuation">.</span><span class="token function">commitTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span><span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">{</span>
            <span class="token comment">// 终止事务</span>
            kafkaProducer<span class="token punctuation">.</span><span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span><span class="token keyword">finally</span> <span class="token punctuation">{</span>
            <span class="token comment">// 7. 关闭资源</span>
            kafkaProducer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><h4 id="_3-8-生产经验-数据有序" tabindex="-1"><a class="header-anchor" href="#_3-8-生产经验-数据有序" aria-hidden="true">#</a> 3.8 生产经验-----数据有序</h4><p><img src="`+I+'" alt="23"></p><h4 id="_3-9-生产经验-数据乱序" tabindex="-1"><a class="header-anchor" href="#_3-9-生产经验-数据乱序" aria-hidden="true">#</a> 3.9 生产经验-----数据乱序</h4><p>1、kafka在1.x 版本之前保证数据单分区有序，条件如下：</p><p>​ <strong>max.in.flight.requests.per.connection</strong>=1（不需要考虑是否开启幂等性）。</p><p>2、kafka在1.x及以后版本保证数据单分区有序，条件如下：</p><ul><li><p><strong>未开启幂等性</strong></p><p><strong>max.in.flight.requests.per.connection</strong> 需要设置为1。</p></li><li><p><strong>开启幂等性</strong></p><p><strong>max.in.flight.requests.per.connection</strong> 需要设置小于等于5。</p></li></ul><p>原因说明：因为在kafka1.x以后，启用幂等后，kafka服务端会缓存producer发来的最近5个request的元数据，</p><p>故无论如何，都可以保证最近5个request的数据都是有序的。</p><p><img src="'+j+`" alt="24"></p><h3 id="四、kafka-broker" tabindex="-1"><a class="header-anchor" href="#四、kafka-broker" aria-hidden="true">#</a> 四、<strong>Kafka Broker</strong></h3><h4 id="_4-1-kafka-broker-工作流程" tabindex="-1"><a class="header-anchor" href="#_4-1-kafka-broker-工作流程" aria-hidden="true">#</a> <strong>4.1 Kafka Broker</strong> <strong>工作流程</strong></h4><h5 id="_4-1-1-zookeeper-存储的-kafka-信息" tabindex="-1"><a class="header-anchor" href="#_4-1-1-zookeeper-存储的-kafka-信息" aria-hidden="true">#</a> <strong>4.1.1 Zookeeper</strong> <strong>存储的</strong> <strong>Kafka</strong> <strong>信息</strong></h5><ol><li>启动Zookeeper客户端</li></ol><div class="language-basic" data-ext="basic"><pre class="language-basic"><code>yooome@<span class="token number">192</span> zookeeper % .<span class="token operator">/</span>bin<span class="token operator">/</span>zkCli.sh 
</code></pre></div><ol start="2"><li>通过ls命令可以查看kafka相关信息</li></ol><div class="language-basic" data-ext="basic"><pre class="language-basic"><code>[zk<span class="token punctuation">:</span> localhost<span class="token punctuation">:</span><span class="token number">2181</span><span class="token punctuation">(</span>CONNECTING<span class="token punctuation">)</span> <span class="token number">0</span>] ls <span class="token operator">/</span>
</code></pre></div><ol start="3"><li>Zookeeper中存储的Kafka信息</li></ol><div class="language-basic" data-ext="basic"><pre class="language-basic"><code>[zk<span class="token punctuation">:</span> localhost<span class="token punctuation">:</span><span class="token number">2181</span><span class="token punctuation">(</span>CONNECTING<span class="token punctuation">)</span> <span class="token number">0</span>] ls <span class="token operator">/</span>
[admin<span class="token punctuation">,</span> brokers<span class="token punctuation">,</span> cluster<span class="token punctuation">,</span> config<span class="token punctuation">,</span> consumers<span class="token punctuation">,</span> controller<span class="token punctuation">,</span> controller_epoch<span class="token punctuation">,</span> feature<span class="token punctuation">,</span> isr_change_notification<span class="token punctuation">,</span> latest_producer_id_block<span class="token punctuation">,</span> log_dir_event_notification<span class="token punctuation">,</span> zookeeper]
</code></pre></div><p><img src="`+A+'" alt="25"></p><h5 id="_4-1-2-kafka-broker总体工作流程" tabindex="-1"><a class="header-anchor" href="#_4-1-2-kafka-broker总体工作流程" aria-hidden="true">#</a> 4.1.2 Kafka Broker总体工作流程</h5><p><img src="'+L+`" alt="26"></p><p>1、模拟Kafka上下线，Zookeeper中数据变化</p><ul><li>① 查看/kafka/brokers/ids 路径上的节点。</li></ul><div class="language-basci" data-ext="basci"><pre class="language-basci"><code>[zk: localhost:2181(CONNECTED) 2] ls /kafka/brokers/ids
[0, 1, 2]
</code></pre></div><ul><li>② 查看/kafka/controller 路径上的数据。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> <span class="token number">15</span><span class="token punctuation">]</span> get /kafka/controller
<span class="token punctuation">{</span><span class="token string">&quot;version&quot;</span>:1,<span class="token string">&quot;brokerid&quot;</span>:0,<span class="token string">&quot;timestamp&quot;</span><span class="token builtin class-name">:</span><span class="token string">&quot;1637292471777&quot;</span><span class="token punctuation">}</span>
</code></pre></div><ul><li>③ 查看/kafka/brokers/topics/first/partitions/0/state 路径上的数据。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> <span class="token number">16</span><span class="token punctuation">]</span> get /kafka/brokers/topics/first/partitions/0/state
<span class="token punctuation">{</span><span class="token string">&quot;controller_epoch&quot;</span>:24,<span class="token string">&quot;leader&quot;</span>:0,<span class="token string">&quot;version&quot;</span>:1,<span class="token string">&quot;leader_epoch&quot;</span>:18,<span class="token string">&quot;isr&quot;</span>:<span class="token punctuation">[</span><span class="token number">0,1</span>,2<span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre></div><ul><li>④ 停止 hadoop104 上的 kafka。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop104 kafka<span class="token punctuation">]</span>$ bin/kafka-server-stop.sh
</code></pre></div><ul><li>⑤ 再次查看/kafka/brokers/ids 路径上的节点。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> <span class="token number">3</span><span class="token punctuation">]</span> <span class="token function">ls</span> /kafka/brokers/ids
<span class="token punctuation">[</span><span class="token number">0</span>, <span class="token number">1</span><span class="token punctuation">]</span>
</code></pre></div><ul><li>⑥ 再次查看/kafka/controller 路径上的数据。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> <span class="token number">15</span><span class="token punctuation">]</span> get /kafka/controller
<span class="token punctuation">{</span><span class="token string">&quot;version&quot;</span>:1,<span class="token string">&quot;brokerid&quot;</span>:0,<span class="token string">&quot;timestamp&quot;</span><span class="token builtin class-name">:</span><span class="token string">&quot;1637292471777&quot;</span><span class="token punctuation">}</span>
</code></pre></div><ul><li>⑦ 再次查看/kafka/brokers/topics/first/partitions/0/state 路径上的数据。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> <span class="token number">16</span><span class="token punctuation">]</span> get 
/kafka/brokers/topics/first/partitions/0/state
<span class="token punctuation">{</span><span class="token string">&quot;controller_epoch&quot;</span>:24,<span class="token string">&quot;leader&quot;</span>:0,<span class="token string">&quot;version&quot;</span>:1,<span class="token string">&quot;leader_epoch&quot;</span>:18,<span class="token string">&quot;isr&quot;</span>:<span class="token punctuation">[</span><span class="token number">0,1</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre></div><ul><li>⑧ 启动 hadoop104 上的 kafka。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop104 kafka<span class="token punctuation">]</span>$ bin/kafka-server-start.sh -
daemon ./config/server.properties
</code></pre></div><ul><li>⑨ 再次观察（1）、（2）、（3）步骤中的内容。</li></ul><h5 id="_4-1-3-broker重要参数" tabindex="-1"><a class="header-anchor" href="#_4-1-3-broker重要参数" aria-hidden="true">#</a> 4.1.3 Broker重要参数</h5><table><thead><tr><th>参数名称</th><th>描述</th></tr></thead><tbody><tr><td>replica.lag.time.max.ms</td><td>ISR 中，如果 Follower 长时间未向 Leader 发送通<br>信请求或同步数据，则该 Follower 将被踢出 ISR。<br>该时间阈值，默认 30s。</td></tr><tr><td>auto.leader.rebalance.enable</td><td>默认是 true。 自动 Leader Partition 平衡。</td></tr><tr><td>leader.imbalance.per.broker.percentage</td><td>默认是 10%。每个 broker 允许的不平衡的 leader<br>的比率。如果每个 broker 超过了这个值，控制器<br>会触发 leader 的平衡。</td></tr><tr><td>leader.imbalance.check.interval.seconds</td><td>默认值 300 秒。检查 leader 负载是否平衡的间隔时间。</td></tr><tr><td>log.segment.bytes</td><td>间。Kafka 中 log 日志是分成一块块存储的，此配置是指 log 日志划分 成块的大小，默认值 1G。</td></tr><tr><td>log.index.interval.bytes</td><td>默认 4kb，kafka 里面每当写入了 4kb 大小的日志<br>（.log），然后就往 index 文件里面记录一个索引。</td></tr><tr><td>log.retention.hours</td><td>Kafka 中数据保存的时间，默认 7 天。</td></tr><tr><td>log.retention.minutes</td><td>Kafka 中数据保存的时间，分钟级别，默认关闭。</td></tr><tr><td>log.retention.ms</td><td>Kafka 中数据保存的时间，毫秒级别，默认关闭。</td></tr><tr><td>log.retention.check.interval.ms</td><td>检查数据是否保存超时的间隔，默认是 5 分钟。</td></tr><tr><td>log.retention.bytes</td><td>默认等于-1，表示无穷大。超过设置的所有日志总<br>大小，删除最早的 segment。</td></tr><tr><td>log.cleanup.policy</td><td>默认是 delete，表示所有数据启用删除策略；<br>如果设置值为 compact，表示所有数据启用压缩策<br>略。</td></tr><tr><td>num.io.threads</td><td>默认是 8。负责写磁盘的线程数。整个参数值要占<br>总核数的 50%。</td></tr><tr><td>num.replica.fetchers</td><td>副本拉取线程数，这个参数占总核数的 50%的 1/3</td></tr><tr><td>num.network.threads</td><td>默认是 3。数据传输线程数，这个参数占总核数的<br>50%的 2/3 。</td></tr><tr><td>log.flush.interval.messages</td><td>强制页缓存刷写到磁盘的条数，默认是 long 的最<br>大值，9223372036854775807。一般不建议修改，<br>交给系统自己管理。</td></tr><tr><td>log.flush.interval.ms</td><td>每隔多久，刷数据到磁盘，默认是 null。一般不建<br>议修改，交给系统自己管理。</td></tr></tbody></table><h4 id="_4-2-生产经验-节点服役和退役" tabindex="-1"><a class="header-anchor" href="#_4-2-生产经验-节点服役和退役" aria-hidden="true">#</a> 4.2 生产经验-----节点服役和退役</h4><h5 id="_4-2-1-服役新节点" tabindex="-1"><a class="header-anchor" href="#_4-2-1-服役新节点" aria-hidden="true">#</a> 4.2.1 服役新节点</h5><p><strong>1、新节点准备</strong></p><ul><li>① 关闭hadoop104，并右键执行克隆操作。</li><li>② 开启hadoop105，并修改IP地址。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>root@hadoop104 ~<span class="token punctuation">]</span><span class="token comment"># vim /etc/sysconfig/network-scripts/ifcfg-ens33</span>
<span class="token assign-left variable">DEVICE</span><span class="token operator">=</span>ens33
<span class="token assign-left variable">TYPE</span><span class="token operator">=</span>Ethernet
<span class="token assign-left variable">ONBOOT</span><span class="token operator">=</span>yes
<span class="token assign-left variable">BOOTPROTO</span><span class="token operator">=</span>static
<span class="token assign-left variable">NAME</span><span class="token operator">=</span><span class="token string">&quot;ens33&quot;</span>
<span class="token assign-left variable">IPADDR</span><span class="token operator">=</span><span class="token number">192.168</span>.10.105
<span class="token assign-left variable">PREFIX</span><span class="token operator">=</span><span class="token number">24</span>
<span class="token assign-left variable">GATEWAY</span><span class="token operator">=</span><span class="token number">192.168</span>.10.2
<span class="token assign-left variable">DNS1</span><span class="token operator">=</span><span class="token number">192.168</span>.10.2
</code></pre></div><ul><li>③ 在hadoop105 上修改主机名称为hadoop105。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>root@hadoop104 ~<span class="token punctuation">]</span><span class="token comment"># vim /etc/hostname</span>
hadoop105
</code></pre></div><ul><li><p>④ 重新启动hadoop104、hadoop105</p></li><li><p>⑤ 修改 haodoop105 中 kafka 的 broker.id 为 3。</p></li><li><p>⑥ 删除 hadoop105 中 kafka 下的 datas 和 logs。</p></li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop105 kafka<span class="token punctuation">]</span>$ <span class="token function">rm</span> <span class="token parameter variable">-rf</span> datas/* logs/*
</code></pre></div><ul><li>⑦ 启动 hadoop102、hadoop103、hadoop104 上的 kafka 集群。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 ~<span class="token punctuation">]</span>$ zk.sh start
<span class="token punctuation">[</span>atguigu@hadoop102 ~<span class="token punctuation">]</span>$ kf.sh start
</code></pre></div><ul><li>⑧ 单独启动 hadoop105 中的 kafka。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop105 kafka<span class="token punctuation">]</span>$ bin/kafka-server-start.sh -
daemon ./config/server.properties
</code></pre></div><p><strong>2、执行负载均衡操作</strong></p><ul><li>① 创建一个要均衡的主题</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ <span class="token function">vim</span> topics-to-move.json
<span class="token punctuation">{</span>
  <span class="token string">&quot;topics&quot;</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span>
  <span class="token punctuation">{</span><span class="token string">&quot;topic&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;first&quot;</span><span class="token punctuation">}</span>
  <span class="token punctuation">]</span>,
  <span class="token string">&quot;version&quot;</span><span class="token builtin class-name">:</span> <span class="token number">1</span>
<span class="token punctuation">}</span>
</code></pre></div><ul><li>② 生成一个负载均衡的计划</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-reassign-partitions.sh --
bootstrap-server hadoop102:9092 --topics-to-move-json-file 
topics-to-move.json --broker-list <span class="token string">&quot;0,1,2,3&quot;</span> <span class="token parameter variable">--generate</span>
Current partition replica assignment
<span class="token punctuation">{</span><span class="token string">&quot;version&quot;</span>:1,<span class="token string">&quot;partitions&quot;</span>:<span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">&quot;topic&quot;</span><span class="token builtin class-name">:</span><span class="token string">&quot;first&quot;</span>,<span class="token string">&quot;partition&quot;</span>:0,<span class="token string">&quot;replic
as&quot;</span>:<span class="token punctuation">[</span><span class="token number">0,2</span>,1<span class="token punctuation">]</span>,<span class="token string">&quot;log_dirs&quot;</span>:<span class="token punctuation">[</span><span class="token string">&quot;any&quot;</span>,<span class="token string">&quot;any&quot;</span>,<span class="token string">&quot;any&quot;</span><span class="token punctuation">]</span><span class="token punctuation">}</span>,<span class="token punctuation">{</span><span class="token string">&quot;topic&quot;</span><span class="token builtin class-name">:</span><span class="token string">&quot;first&quot;</span>,<span class="token string">&quot;par
tition&quot;</span>:1,<span class="token string">&quot;replicas&quot;</span>:<span class="token punctuation">[</span><span class="token number">2,1</span>,0<span class="token punctuation">]</span>,<span class="token string">&quot;log_dirs&quot;</span>:<span class="token punctuation">[</span><span class="token string">&quot;any&quot;</span>,<span class="token string">&quot;any&quot;</span>,<span class="token string">&quot;any&quot;</span><span class="token punctuation">]</span><span class="token punctuation">}</span>,<span class="token punctuation">{</span><span class="token string">&quot;to
pic&quot;</span><span class="token builtin class-name">:</span><span class="token string">&quot;first&quot;</span>,<span class="token string">&quot;partition&quot;</span>:2,<span class="token string">&quot;replicas&quot;</span>:<span class="token punctuation">[</span><span class="token number">1,0</span>,2<span class="token punctuation">]</span>,<span class="token string">&quot;log_dirs&quot;</span>:<span class="token punctuation">[</span><span class="token string">&quot;any&quot;</span>,<span class="token string">&quot;
any&quot;</span>,<span class="token string">&quot;any&quot;</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
Proposed partition reassignment configuration
<span class="token punctuation">{</span><span class="token string">&quot;version&quot;</span>:1,<span class="token string">&quot;partitions&quot;</span>:<span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">&quot;topic&quot;</span><span class="token builtin class-name">:</span><span class="token string">&quot;first&quot;</span>,<span class="token string">&quot;partition&quot;</span>:0,<span class="token string">&quot;replic
as&quot;</span>:<span class="token punctuation">[</span><span class="token number">2,3</span>,0<span class="token punctuation">]</span>,<span class="token string">&quot;log_dirs&quot;</span>:<span class="token punctuation">[</span><span class="token string">&quot;any&quot;</span>,<span class="token string">&quot;any&quot;</span>,<span class="token string">&quot;any&quot;</span><span class="token punctuation">]</span><span class="token punctuation">}</span>,<span class="token punctuation">{</span><span class="token string">&quot;topic&quot;</span><span class="token builtin class-name">:</span><span class="token string">&quot;first&quot;</span>,<span class="token string">&quot;par
tition&quot;</span>:1,<span class="token string">&quot;replicas&quot;</span>:<span class="token punctuation">[</span><span class="token number">3,0</span>,1<span class="token punctuation">]</span>,<span class="token string">&quot;log_dirs&quot;</span>:<span class="token punctuation">[</span><span class="token string">&quot;any&quot;</span>,<span class="token string">&quot;any&quot;</span>,<span class="token string">&quot;any&quot;</span><span class="token punctuation">]</span><span class="token punctuation">}</span>,<span class="token punctuation">{</span><span class="token string">&quot;to
pic&quot;</span><span class="token builtin class-name">:</span><span class="token string">&quot;first&quot;</span>,<span class="token string">&quot;partition&quot;</span>:2,<span class="token string">&quot;replicas&quot;</span>:<span class="token punctuation">[</span><span class="token number">0,1</span>,2<span class="token punctuation">]</span>,<span class="token string">&quot;log_dirs&quot;</span>:<span class="token punctuation">[</span><span class="token string">&quot;any&quot;</span>,<span class="token string">&quot;
any&quot;</span>,<span class="token string">&quot;any&quot;</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre></div><ul><li>③ 创建副本存储计划（所有副本存储在 broker0、broker1、broker2、broker3中)。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ <span class="token function">vim</span> increase-replication-factor.json
</code></pre></div><p>输入如下内容：</p><div class="language-json" data-ext="json"><pre class="language-json"><code><span class="token punctuation">{</span><span class="token property">&quot;version&quot;</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token property">&quot;partitions&quot;</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">&quot;topic&quot;</span><span class="token operator">:</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;partition&quot;</span><span class="token operator">:</span><span class="token number">0</span><span class="token punctuation">,</span>&quot;replic
as<span class="token string">&quot;:[2,3,0],&quot;</span>log_dirs<span class="token string">&quot;:[&quot;</span>any<span class="token string">&quot;,&quot;</span>any<span class="token string">&quot;,&quot;</span>any<span class="token string">&quot;]},{&quot;</span>topic<span class="token string">&quot;:&quot;</span>first<span class="token string">&quot;,&quot;</span>par
tition<span class="token string">&quot;:1,&quot;</span>replicas<span class="token string">&quot;:[3,0,1],&quot;</span>log_dirs<span class="token string">&quot;:[&quot;</span>any<span class="token string">&quot;,&quot;</span>any<span class="token string">&quot;,&quot;</span>any<span class="token string">&quot;]},{&quot;</span>to
pic<span class="token string">&quot;:&quot;</span>first<span class="token string">&quot;,&quot;</span>partition<span class="token string">&quot;:2,&quot;</span>replicas<span class="token string">&quot;:[0,1,2],&quot;</span>log_dirs<span class="token string">&quot;:[&quot;</span>any<span class="token string">&quot;,&quot;</span>
any<span class="token string">&quot;,&quot;</span>any&quot;<span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre></div><ul><li>④ 执行副本存储计划</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-reassign-partitions.sh --
bootstrap-server hadoop102:9092 --reassignment-json-file 
increase-replication-factor.json <span class="token parameter variable">--execute</span>
</code></pre></div><ul><li>⑤ 验证副本存储计划。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-reassign-partitions.sh --
bootstrap-server hadoop102:9092 --reassignment-json-file 
increase-replication-factor.json <span class="token parameter variable">--verify</span>
Status of partition reassignment:
Reassignment of partition first-0 is complete.
Reassignment of partition first-1 is complete.
Reassignment of partition first-2 is complete.
Clearing broker-level throttles on brokers <span class="token number">0,1</span>,2,3
Clearing topic-level throttles on topic first
</code></pre></div><h5 id="_4-2-2-退役旧节点" tabindex="-1"><a class="header-anchor" href="#_4-2-2-退役旧节点" aria-hidden="true">#</a> 4.2.2 退役旧节点</h5><p><strong>1、执行负载均衡操作</strong></p><p>先按照退役一台节点，生成执行计划，然后按照服役时操作流程执行负载均衡。</p><ul><li>① 创建一个要均衡的主题。</li></ul><div class="language-json" data-ext="json"><pre class="language-json"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ vim topics-to-move.json
<span class="token punctuation">{</span>
  <span class="token property">&quot;topics&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
  <span class="token punctuation">{</span><span class="token property">&quot;topic&quot;</span><span class="token operator">:</span> <span class="token string">&quot;first&quot;</span><span class="token punctuation">}</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token property">&quot;version&quot;</span><span class="token operator">:</span> <span class="token number">1</span>
<span class="token punctuation">}</span>
</code></pre></div><ul><li>② 创建执行计划。</li></ul><div class="language-json" data-ext="json"><pre class="language-json"><code>bootstrap-server hadoop102<span class="token operator">:</span><span class="token number">9092</span> --topics-to-move-json-file 
topics-to-move.json --broker-list <span class="token string">&quot;0,1,2&quot;</span> --generate
Current partition replica assignment
<span class="token punctuation">{</span><span class="token property">&quot;version&quot;</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token property">&quot;partitions&quot;</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">&quot;topic&quot;</span><span class="token operator">:</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;partition&quot;</span><span class="token operator">:</span><span class="token number">0</span><span class="token punctuation">,</span>&quot;replic
as<span class="token string">&quot;:[2,0,1],&quot;</span>log_dirs<span class="token string">&quot;:[&quot;</span>any<span class="token string">&quot;,&quot;</span>any<span class="token string">&quot;,&quot;</span>any<span class="token string">&quot;]},{&quot;</span>topic<span class="token string">&quot;:&quot;</span>first<span class="token string">&quot;,&quot;</span>par
tition<span class="token string">&quot;:1,&quot;</span>replicas<span class="token string">&quot;:[3,1,2],&quot;</span>log_dirs<span class="token string">&quot;:[&quot;</span>any<span class="token string">&quot;,&quot;</span>any<span class="token string">&quot;,&quot;</span>any<span class="token string">&quot;]},{&quot;</span>to
pic<span class="token string">&quot;:&quot;</span>first<span class="token string">&quot;,&quot;</span>partition<span class="token string">&quot;:2,&quot;</span>replicas<span class="token string">&quot;:[0,2,3],&quot;</span>log_dirs<span class="token string">&quot;:[&quot;</span>any<span class="token string">&quot;,&quot;</span>
any<span class="token string">&quot;,&quot;</span>any&quot;<span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
Proposed partition reassignment configuration
<span class="token punctuation">{</span><span class="token property">&quot;version&quot;</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token property">&quot;partitions&quot;</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">&quot;topic&quot;</span><span class="token operator">:</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;partition&quot;</span><span class="token operator">:</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token property">&quot;replicas&quot;</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">&quot;log_dirs&quot;</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">&quot;any&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;any&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;any&quot;</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">{</span><span class="token property">&quot;topic&quot;</span><span class="token operator">:</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">,</span>&quot;par
tition<span class="token string">&quot;:1,&quot;</span>replicas<span class="token string">&quot;:[0,1,2],&quot;</span>log_dirs<span class="token string">&quot;:[&quot;</span>any<span class="token string">&quot;,&quot;</span>any<span class="token string">&quot;,&quot;</span>any<span class="token string">&quot;]},{&quot;</span>to
pic<span class="token string">&quot;:&quot;</span>first<span class="token string">&quot;,&quot;</span>partition<span class="token string">&quot;:2,&quot;</span>replicas<span class="token string">&quot;:[1,2,0],&quot;</span>log_dirs<span class="token string">&quot;:[&quot;</span>any<span class="token string">&quot;,&quot;</span>
any<span class="token string">&quot;,&quot;</span>any&quot;<span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre></div><ul><li>③ 创建副本存储计划（所有副本存储在 broker0、broker1、broker2 中）。</li></ul><div class="language-json" data-ext="json"><pre class="language-json"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ vim increase-replication-factor.json
<span class="token punctuation">{</span><span class="token property">&quot;version&quot;</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token property">&quot;partitions&quot;</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">&quot;topic&quot;</span><span class="token operator">:</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;partition&quot;</span><span class="token operator">:</span><span class="token number">0</span><span class="token punctuation">,</span>&quot;replic
as<span class="token string">&quot;:[2,0,1],&quot;</span>log_dirs<span class="token string">&quot;:[&quot;</span>any<span class="token string">&quot;,&quot;</span>any<span class="token string">&quot;,&quot;</span>any<span class="token string">&quot;]},{&quot;</span>topic<span class="token string">&quot;:&quot;</span>first<span class="token string">&quot;,&quot;</span>par
tition<span class="token string">&quot;:1,&quot;</span>replicas<span class="token string">&quot;:[0,1,2],&quot;</span>log_dirs<span class="token string">&quot;:[&quot;</span>any<span class="token string">&quot;,&quot;</span>any<span class="token string">&quot;,&quot;</span>any<span class="token string">&quot;]},{&quot;</span>to
pic<span class="token string">&quot;:&quot;</span>first<span class="token string">&quot;,&quot;</span>partition<span class="token string">&quot;:2,&quot;</span>replicas<span class="token string">&quot;:[1,2,0],&quot;</span>log_dirs<span class="token string">&quot;:[&quot;</span>any<span class="token string">&quot;,&quot;</span>
any<span class="token string">&quot;,&quot;</span>any&quot;<span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre></div><ul><li>④ 执行副本存储计划。</li></ul><div class="language-json" data-ext="json"><pre class="language-json"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-reassign-partitions.sh --
bootstrap-server hadoop102<span class="token operator">:</span><span class="token number">9092</span> --reassignment-json-file 
increase-replication-factor.json --execute
</code></pre></div><ul><li>⑤ 验证副本存储计划。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-reassign-partitions.sh --
bootstrap-server hadoop102:9092 --reassignment-json-file 
increase-replication-factor.json <span class="token parameter variable">--verify</span>
Status of partition reassignment:
Reassignment of partition first-0 is complete.
Reassignment of partition first-1 is complete.
Reassignment of partition first-2 is complete.
Clearing broker-level throttles on brokers <span class="token number">0,1</span>,2,3
Clearing topic-level throttles on topic first
</code></pre></div><p><strong>2、执行停止命令</strong></p><p>在hadoop105 上执行停止命令即可</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop105 kafka<span class="token punctuation">]</span>$ bin/kafka-server-stop.sh
</code></pre></div><h4 id="_4-3-kafka副本" tabindex="-1"><a class="header-anchor" href="#_4-3-kafka副本" aria-hidden="true">#</a> 4.3 Kafka副本</h4><h5 id="_4-3-1-副本基本信息" tabindex="-1"><a class="header-anchor" href="#_4-3-1-副本基本信息" aria-hidden="true">#</a> 4.3.1 副本基本信息</h5><ol><li>Kafka副本作用：提高数据可靠性。</li><li>Kafka默认副本1个，生产环境一般配置为2个，保证数据可靠性；太多副本会增加磁盘存储空间，增加网络上数据传输，降低效率。</li><li>Kafka中副本为：Leader和Follower。Kafka生产者只会把数据发往 Leader，然后Follower 找 Leader 进行同步数据。</li><li>Kafka 分区中的所有副本统称为 AR（Assigned Repllicas）。</li></ol><p>AR = ISR + OSR</p><p><strong>ISR</strong>：表示 Leader 保持同步的 Follower 集合。如果 Follower 长时间未 向 Leader 发送通信请求或同步数据，则该 Follower 将被踢出 ISR。该时间阈值由 <strong>replica.lag.time.max.ms</strong> 参数设定，默认 30s 。Leader 发生故障之后，就会从 ISR 中选举新的 Leader。</p><p><strong>OSR</strong>：表示 Follower 与 Leader 副本同步时，延迟过多的副本。</p><h5 id="_4-3-2-leader-选举流程" tabindex="-1"><a class="header-anchor" href="#_4-3-2-leader-选举流程" aria-hidden="true">#</a> 4.3.2 Leader 选举流程</h5><p>​ Kafka 集群中有一个 broker 的 Controller 会被选举为 Controller Leader ，负责管理集群 broker 的上下线，所有 topic 的分区副本分配 和 Leader 选举等工作。</p><p><img src="`+T+`" alt="27"></p><ol><li>创建一个新的 topic，4 个分区，4 个副本</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--create</span> <span class="token parameter variable">--topic</span> atguigu1 <span class="token parameter variable">--partitions</span> <span class="token number">4</span> --replication-factor 
<span class="token number">4</span>
Created topic atguigu1.
</code></pre></div><ol start="2"><li>查看 Leader 分布情况</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--describe</span> 
<span class="token parameter variable">--topic</span> atguigu1
Topic: atguigu1 TopicId: awpgX_7WR-OX3Vl6HE8sVg PartitionCount: <span class="token number">4</span> ReplicationFactor: <span class="token number">4</span>
Configs: <span class="token assign-left variable">segment.bytes</span><span class="token operator">=</span><span class="token number">1073741824</span>
Topic: atguigu1 Partition: <span class="token number">0</span> Leader: <span class="token number">3</span> Replicas: <span class="token number">3,0</span>,2,1 Isr: <span class="token number">3,0</span>,2,1
Topic: atguigu1 Partition: <span class="token number">1</span> Leader: <span class="token number">1</span> Replicas: <span class="token number">1,2</span>,3,0 Isr: <span class="token number">1,2</span>,3,0
Topic: atguigu1 Partition: <span class="token number">2</span> Leader: <span class="token number">0</span> Replicas: <span class="token number">0,3</span>,1,2 Isr: <span class="token number">0,3</span>,1,2
Topic: atguigu1 Partition: <span class="token number">3</span> Leader: <span class="token number">2</span> Replicas: <span class="token number">2,1</span>,0,3 Isr: <span class="token number">2,1</span>,0,3
</code></pre></div><ol start="3"><li>停止掉 hadoop105 的 kafka 进程，并查看 Leader 分区情况</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop105 kafka<span class="token punctuation">]</span>$ bin/kafka-server-stop.sh
<span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--describe</span> 
<span class="token parameter variable">--topic</span> atguigu1
Topic: atguigu1 TopicId: awpgX_7WR-OX3Vl6HE8sVg PartitionCount: <span class="token number">4</span> ReplicationFactor: <span class="token number">4</span>
Configs: <span class="token assign-left variable">segment.bytes</span><span class="token operator">=</span><span class="token number">1073741824</span>
Topic: atguigu1 Partition: <span class="token number">0</span> Leader: <span class="token number">0</span> Replicas: <span class="token number">3,0</span>,2,1 Isr: <span class="token number">0,2</span>,1
Topic: atguigu1 Partition: <span class="token number">1</span> Leader: <span class="token number">1</span> Replicas: <span class="token number">1,2</span>,3,0 Isr: <span class="token number">1,2</span>,0
Topic: atguigu1 Partition: <span class="token number">2</span> Leader: <span class="token number">0</span> Replicas: <span class="token number">0,3</span>,1,2 Isr: <span class="token number">0,1</span>,2
Topic: atguigu1 Partition: <span class="token number">3</span> Leader: <span class="token number">2</span> Replicas: <span class="token number">2,1</span>,0,3 Isr: <span class="token number">2,1</span>,0
</code></pre></div><ol start="4"><li>停止掉 hadoop104 的 kafka 进程，并查看 Leader 分区情况</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop104 kafka<span class="token punctuation">]</span>$ bin/kafka-server-stop.sh
<span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--describe</span> 
<span class="token parameter variable">--topic</span> atguigu1
Topic: atguigu1 TopicId: awpgX_7WR-OX3Vl6HE8sVg PartitionCount: <span class="token number">4</span> ReplicationFactor: <span class="token number">4</span>
Configs: <span class="token assign-left variable">segment.bytes</span><span class="token operator">=</span><span class="token number">1073741824</span>
Topic: atguigu1 Partition: <span class="token number">0</span> Leader: <span class="token number">0</span> Replicas: <span class="token number">3,0</span>,2,1 Isr: <span class="token number">0,1</span>
Topic: atguigu1 Partition: <span class="token number">1</span> Leader: <span class="token number">1</span> Replicas: <span class="token number">1,2</span>,3,0 Isr: <span class="token number">1,0</span>
Topic: atguigu1 Partition: <span class="token number">2</span> Leader: <span class="token number">0</span> Replicas: <span class="token number">0,3</span>,1,2 Isr: <span class="token number">0,1</span>
Topic: atguigu1 Partition: <span class="token number">3</span> Leader: <span class="token number">1</span> Replicas: <span class="token number">2,1</span>,0,3 Isr: <span class="token number">1,0</span>
</code></pre></div><ol start="5"><li>启动 hadoop105 的 kafka 进程，并查看 Leader 分区情况</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop105 kafka<span class="token punctuation">]</span>$ bin/kafka-server-start.sh <span class="token parameter variable">-daemon</span> config/server.properties
<span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--describe</span> 
<span class="token parameter variable">--topic</span> atguigu1
Topic: atguigu1 TopicId: awpgX_7WR-OX3Vl6HE8sVg PartitionCount: <span class="token number">4</span> ReplicationFactor: <span class="token number">4</span>
Configs: <span class="token assign-left variable">segment.bytes</span><span class="token operator">=</span><span class="token number">1073741824</span>
Topic: atguigu1 Partition: <span class="token number">0</span> Leader: <span class="token number">0</span> Replicas: <span class="token number">3,0</span>,2,1 Isr: <span class="token number">0,1</span>,3
Topic: atguigu1 Partition: <span class="token number">1</span> Leader: <span class="token number">1</span> Replicas: <span class="token number">1,2</span>,3,0 Isr: <span class="token number">1,0</span>,3
Topic: atguigu1 Partition: <span class="token number">2</span> Leader: <span class="token number">0</span> Replicas: <span class="token number">0,3</span>,1,2 Isr: <span class="token number">0,1</span>,3
Topic: atguigu1 Partition: <span class="token number">3</span> Leader: <span class="token number">1</span> Replicas: <span class="token number">2,1</span>,0,3 Isr: <span class="token number">1,0</span>,3
</code></pre></div><ol start="6"><li>启动 hadoop104 的 kafka 进程，并查看 Leader 分区情况</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop104 kafka<span class="token punctuation">]</span>$ bin/kafka-server-start.sh <span class="token parameter variable">-daemon</span> config/server.properties
<span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--describe</span> 
<span class="token parameter variable">--topic</span> atguigu1
Topic: atguigu1 TopicId: awpgX_7WR-OX3Vl6HE8sVg PartitionCount: <span class="token number">4</span> ReplicationFactor: <span class="token number">4</span>
Configs: <span class="token assign-left variable">segment.bytes</span><span class="token operator">=</span><span class="token number">1073741824</span>
Topic: atguigu1 Partition: <span class="token number">0</span> Leader: <span class="token number">0</span> Replicas: <span class="token number">3,0</span>,2,1 Isr: <span class="token number">0,1</span>,3,2
Topic: atguigu1 Partition: <span class="token number">1</span> Leader: <span class="token number">1</span> Replicas: <span class="token number">1,2</span>,3,0 Isr: <span class="token number">1,0</span>,3,2
Topic: atguigu1 Partition: <span class="token number">2</span> Leader: <span class="token number">0</span> Replicas: <span class="token number">0,3</span>,1,2 Isr: <span class="token number">0,1</span>,3,2
Topic: atguigu1 Partition: <span class="token number">3</span> Leader: <span class="token number">1</span> Replicas: <span class="token number">2,1</span>,0,3 Isr: <span class="token number">1,0</span>,3,2
</code></pre></div><ol start="7"><li>停止掉 hadoop103 的 kafka 进程，并查看 Leader 分区情况</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop103 kafka<span class="token punctuation">]</span>$ bin/kafka-server-stop.sh
<span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--describe</span> 
<span class="token parameter variable">--topic</span> atguigu1
Topic: atguigu1 TopicId: awpgX_7WR-OX3Vl6HE8sVg PartitionCount: <span class="token number">4</span> ReplicationFactor: <span class="token number">4</span>
Configs: <span class="token assign-left variable">segment.bytes</span><span class="token operator">=</span><span class="token number">1073741824</span>
Topic: atguigu1 Partition: <span class="token number">0</span> Leader: <span class="token number">0</span> Replicas: <span class="token number">3,0</span>,2,1 Isr: <span class="token number">0,3</span>,2
Topic: atguigu1 Partition: <span class="token number">1</span> Leader: <span class="token number">2</span> Replicas: <span class="token number">1,2</span>,3,0 Isr: <span class="token number">0,3</span>,2
Topic: atguigu1 Partition: <span class="token number">2</span> Leader: <span class="token number">0</span> Replicas: <span class="token number">0,3</span>,1,2 Isr: <span class="token number">0,3</span>,2
Topic: atguigu1 Partition: <span class="token number">3</span> Leader: <span class="token number">2</span> Replicas: <span class="token number">2,1</span>,0,3 Isr: <span class="token number">0,3</span>,2
</code></pre></div><h5 id="_4-3-3-leader-和-follower-故障处理细节" tabindex="-1"><a class="header-anchor" href="#_4-3-3-leader-和-follower-故障处理细节" aria-hidden="true">#</a> 4.3.3 Leader 和 Follower 故障处理细节</h5><p><strong>LEO（Log End Offset）</strong>: 每个副本的最后一个offset，LEO其实就是最新的 offset + 1。</p><p><strong>HW（High Watermark）</strong>：所有副本中最小的LEO。</p><p><img src="`+O+'" alt="28"></p><p><strong>LEO</strong>（<strong>Log End Offset</strong>）：每个副本的最后一个offset，LEO其实就是最新的offset + 1</p><p><strong>HW</strong>（<strong>High Watermark</strong>）：所有副本中最小的LEO</p><p><img src="'+K+`" alt="29"></p><h5 id="_4-3-4-分区副本分配" tabindex="-1"><a class="header-anchor" href="#_4-3-4-分区副本分配" aria-hidden="true">#</a> 4.3.4 分区副本分配</h5><p>如果kafka服务器只有 4 个节点，那么设置kafka的分区数大于服务器台数，在kafka底层如何分配存储副本呢？</p><p>1、创建16分区，3个副本。</p><ul><li>① 创建一个新的topic ，名称为 sedond 。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server 
hadoop102:9092 <span class="token parameter variable">--create</span> <span class="token parameter variable">--partitions</span> <span class="token number">16</span> --replication-factor <span class="token number">3</span> --
topic second
</code></pre></div><ul><li>② 查看分区和副本情况。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server 
hadoop102:9092 <span class="token parameter variable">--describe</span> <span class="token parameter variable">--topic</span> second
Topic: second4 Partition: <span class="token number">0</span> Leader: <span class="token number">0</span> Replicas: <span class="token number">0,1</span>,2 Isr: <span class="token number">0,1</span>,2
Topic: second4 Partition: <span class="token number">1</span> Leader: <span class="token number">1</span> Replicas: <span class="token number">1,2</span>,3 Isr: <span class="token number">1,2</span>,3
Topic: second4 Partition: <span class="token number">2</span> Leader: <span class="token number">2</span> Replicas: <span class="token number">2,3</span>,0 Isr: <span class="token number">2,3</span>,0
Topic: second4 Partition: <span class="token number">3</span> Leader: <span class="token number">3</span> Replicas: <span class="token number">3,0</span>,1 Isr: <span class="token number">3,0</span>,1
Topic: second4 Partition: <span class="token number">4</span> Leader: <span class="token number">0</span> Replicas: <span class="token number">0,2</span>,3 Isr: <span class="token number">0,2</span>,3
Topic: second4 Partition: <span class="token number">5</span> Leader: <span class="token number">1</span> Replicas: <span class="token number">1,3</span>,0 Isr: <span class="token number">1,3</span>,0
Topic: second4 Partition: <span class="token number">6</span> Leader: <span class="token number">2</span> Replicas: <span class="token number">2,0</span>,1 Isr: <span class="token number">2,0</span>,1
Topic: second4 Partition: <span class="token number">7</span> Leader: <span class="token number">3</span> Replicas: <span class="token number">3,1</span>,2 Isr: <span class="token number">3,1</span>,2
Topic: second4 Partition: <span class="token number">8</span> Leader: <span class="token number">0</span> Replicas: <span class="token number">0,3</span>,1 Isr: <span class="token number">0,3</span>,1
Topic: second4 Partition: <span class="token number">9</span> Leader: <span class="token number">1</span> Replicas: <span class="token number">1,0</span>,2 Isr: <span class="token number">1,0</span>,2
Topic: second4 Partition: <span class="token number">10</span> Leader: <span class="token number">2</span> Replicas: <span class="token number">2,1</span>,3 Isr: <span class="token number">2,1</span>,3
Topic: second4 Partition: <span class="token number">11</span> Leader: <span class="token number">3</span> Replicas: <span class="token number">3,2</span>,0 Isr: <span class="token number">3,2</span>,0
Topic: second4 Partition: <span class="token number">12</span> Leader: <span class="token number">0</span> Replicas: <span class="token number">0,1</span>,2 Isr: <span class="token number">0,1</span>,2
Topic: second4 Partition: <span class="token number">13</span> Leader: <span class="token number">1</span> Replicas: <span class="token number">1,2</span>,3 Isr: <span class="token number">1,2</span>,3
Topic: second4 Partition: <span class="token number">14</span> Leader: <span class="token number">2</span> Replicas: <span class="token number">2,3</span>,0 Isr: <span class="token number">2,3</span>,0
Topic: second4 Partition: <span class="token number">15</span> Leader: <span class="token number">3</span> Replicas: <span class="token number">3,0</span>,1 Isr: <span class="token number">3,0</span>,1
</code></pre></div><p><img src="`+z+'" alt="30"></p><h5 id="_4-3-5-生产经验-活动调整分区副本存储" tabindex="-1"><a class="header-anchor" href="#_4-3-5-生产经验-活动调整分区副本存储" aria-hidden="true">#</a> 4.3.5 生产经验 --- 活动调整分区副本存储</h5><p>在生产环境中，每台服务器的配置和性能不一致，但是kafka只会根据自己的代码规则创建对应的分区副本，就会导致个别服务器存储压力较大。所有需要手动调整分区副本的存储。</p><p><strong>需求</strong>：创建一个新的 topic ，4个分区，两个副本，名称为three 。将该 topic 的所有副本都存储到 broker0 和 broker1 两台服务器上。</p><p><img src="'+N+`" alt="31"></p><p>手动调整分区副本存储的步骤如下：</p><ol><li>创建一个新的 topic，名称为 three。</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server 
hadoop102:9092 <span class="token parameter variable">--create</span> <span class="token parameter variable">--partitions</span> <span class="token number">4</span> --replication-factor <span class="token number">2</span> --
topic three
</code></pre></div><ol start="2"><li>查看分区副本存储情况</li></ol><div class="language-text" data-ext="text"><pre class="language-text"><code>[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --bootstrap-server 
hadoop102:9092 --describe --topic three
</code></pre></div><ol start="3"><li>创建副本存储计划（所有副本都指定存储在 broker0、broker1 中）。</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ <span class="token function">vim</span> increase-replication-factor.json
</code></pre></div><p>输入如下内容：</p><div class="language-json" data-ext="json"><pre class="language-json"><code><span class="token punctuation">{</span>
  <span class="token property">&quot;version&quot;</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">,</span>
  <span class="token property">&quot;partitions&quot;</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">&quot;topic&quot;</span><span class="token operator">:</span><span class="token string">&quot;three&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;partition&quot;</span><span class="token operator">:</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token property">&quot;replicas&quot;</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span><span class="token property">&quot;topic&quot;</span><span class="token operator">:</span><span class="token string">&quot;three&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;partition&quot;</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token property">&quot;replicas&quot;</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span><span class="token property">&quot;topic&quot;</span><span class="token operator">:</span><span class="token string">&quot;three&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;partition&quot;</span><span class="token operator">:</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token property">&quot;replicas&quot;</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span><span class="token property">&quot;topic&quot;</span><span class="token operator">:</span><span class="token string">&quot;three&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;partition&quot;</span><span class="token operator">:</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token property">&quot;replicas&quot;</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">]</span> 
<span class="token punctuation">}</span>
</code></pre></div><ol start="4"><li>执行副本存储计划。</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-reassign-partitions.sh --
bootstrap-server hadoop102:9092 --reassignment-json-file 
increase-replication-factor.json <span class="token parameter variable">--execute</span>
</code></pre></div><ol start="5"><li>验证副本存储计划。</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-reassign-partitions.sh --
bootstrap-server hadoop102:9092 --reassignment-json-file 
increase-replication-factor.json <span class="token parameter variable">--verify</span>
</code></pre></div><ol start="6"><li>查看分区副本存储情况。</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server 
hadoop102:9092 <span class="token parameter variable">--describe</span> <span class="token parameter variable">--topic</span> three
</code></pre></div><h5 id="_4-3-6-生产经验-leader-partition-负载平衡" tabindex="-1"><a class="header-anchor" href="#_4-3-6-生产经验-leader-partition-负载平衡" aria-hidden="true">#</a> 4.3.6 生产经验 --- Leader Partition 负载平衡</h5><p>​ 正常情况下，Kafka本身会自动把Leader Partition均匀分散在各个机器上，来保证每台机器的读写吞吐量都是均匀的。但是如果某 些broker宕机，会导致Leader Partition过于集中在其他少部分几台broker上，这会导致少数几台broker的读写请求压力过高，其他宕机的broker重启之后都是follower partition，读写请求很低，造成集群负载不均衡。</p><p><img src="`+F+`" alt="32"></p><table><thead><tr><th>参数名称</th><th>描述</th></tr></thead><tbody><tr><td>auto.leader.rebalance.enable</td><td>默认是 true。 自动 Leader Partition 平衡。生产环<br>境中，leader 重选举的代价比较大，可能会带来<br>性能影响，建议设置为 false 关闭。</td></tr><tr><td>leader.imbalance.per.broker.percentage</td><td>默认是 10%。每个 broker 允许的不平衡的 leader<br>的比率。如果每个 broker 超过了这个值，控制器<br>会触发 leader 的平衡。</td></tr><tr><td>leader.imbalance.check.interval.seconds</td><td>默认值 300 秒。检查 leader 负载是否平衡的间隔<br>时间。</td></tr></tbody></table><h5 id="_4-3-7-生产经验-增加副本因子" tabindex="-1"><a class="header-anchor" href="#_4-3-7-生产经验-增加副本因子" aria-hidden="true">#</a> 4.3.7 生产经验 --- 增加副本因子</h5><p>在生产环境当中，由于某个主题的重要等级需要提升，我们考虑增加副本。副本数的</p><p>增加需要先制定计划，然后根据计划执行。</p><ol><li>创建 topic</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server 
hadoop102:9092 <span class="token parameter variable">--create</span> <span class="token parameter variable">--partitions</span> <span class="token number">3</span> --replication-factor <span class="token number">1</span> --
topic four
</code></pre></div><ol start="2"><li>手动增加副本存储</li></ol><ul><li>① 创建副本存储计划（所有副本都指定存储在 broker0、broker1、broker2 中）。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ <span class="token function">vim</span> increase-replication-factor.json
</code></pre></div><p>输入如下内容：</p><div class="language-json" data-ext="json"><pre class="language-json"><code><span class="token punctuation">{</span><span class="token property">&quot;version&quot;</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token property">&quot;partitions&quot;</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">&quot;topic&quot;</span><span class="token operator">:</span><span class="token string">&quot;four&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;partition&quot;</span><span class="token operator">:</span><span class="token number">0</span><span class="token punctuation">,</span>&quot;replica
s<span class="token string">&quot;:[0,1,2]},{&quot;</span>topic<span class="token string">&quot;:&quot;</span>four<span class="token string">&quot;,&quot;</span>partition<span class="token string">&quot;:1,&quot;</span>replicas<span class="token string">&quot;:[0,1,2]},{&quot;</span>t
opic<span class="token string">&quot;:&quot;</span>four<span class="token string">&quot;,&quot;</span>partition<span class="token string">&quot;:2,&quot;</span>replicas&quot;<span class="token operator">:</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre></div><ul><li>② 执行副本存储计划。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-reassign-partitions.sh --
bootstrap-server hadoop102:9092 --reassignment-json-file 
increase-replication-factor.json <span class="token parameter variable">--execute</span>
</code></pre></div><h4 id="_4-4-文件存储" tabindex="-1"><a class="header-anchor" href="#_4-4-文件存储" aria-hidden="true">#</a> 4.4 文件存储</h4><h5 id="_4-4-1-文件存储机制" tabindex="-1"><a class="header-anchor" href="#_4-4-1-文件存储机制" aria-hidden="true">#</a> 4.4.1 文件存储机制</h5><ol><li><strong>Topic 数据的存储机制</strong></li></ol><p><img src="`+$+`" alt="33"></p><ol start="2"><li><strong>思考：Topic数据到底存储在什么位置？</strong></li></ol><ul><li>① 启动生产者，并发送消息。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-console-producer.sh --
bootstrap-server hadoop102:9092 <span class="token parameter variable">--topic</span> first
<span class="token operator">&gt;</span>hello world
</code></pre></div><ul><li>② 查看 hadoop102（或者 hadoop103、hadoop104）的/opt/module/kafka/datas/first-1 （first-0、first-2）路径上的文件</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop104 first-1<span class="token punctuation">]</span>$ <span class="token function">ls</span>
00000000000000000092.index
00000000000000000092.log
00000000000000000092.snapshot
00000000000000000092.timeindex
leader-epoch-checkpoint
partition.metadata
</code></pre></div><ul><li>③ 直接查看 log 日志，发现是乱码。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop104 first-1<span class="token punctuation">]</span>$ <span class="token function">cat</span> 00000000000000000092.log 
<span class="token punctuation">\\</span>CYnF<span class="token operator">|</span>©<span class="token operator">|</span>©ÿÿÿÿÿÿÿÿÿÿÿÿÿÿ&quot;hello world
</code></pre></div><ul><li>④ 通过工具查看 index 和 log 信息。</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop104 first-1<span class="token punctuation">]</span>$ kafka-run-class.sh kafka.tools.DumpLogSegments 
<span class="token parameter variable">--files</span> ./00000000000000000000.index 
Dumping ./00000000000000000000.index
offset: <span class="token number">3</span> position: <span class="token number">152</span>
</code></pre></div><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop104 first-1<span class="token punctuation">]</span>$ kafka-run-class.sh kafka.tools.DumpLogSegments 
<span class="token parameter variable">--files</span> ./00000000000000000000.log
Dumping datas/first-0/00000000000000000000.log
Starting offset: <span class="token number">0</span>
baseOffset: <span class="token number">0</span> lastOffset: <span class="token number">1</span> count: <span class="token number">2</span> baseSequence: <span class="token parameter variable">-1</span> lastSequence: <span class="token parameter variable">-1</span> producerId: <span class="token parameter variable">-1</span> 
producerEpoch: <span class="token parameter variable">-1</span> partitionLeaderEpoch: <span class="token number">0</span> isTransactional: <span class="token boolean">false</span> isControl: <span class="token boolean">false</span> position: 
<span class="token number">0</span> CreateTime: <span class="token number">1636338440962</span> size: <span class="token number">75</span> magic: <span class="token number">2</span> compresscodec: none crc: <span class="token number">2745337109</span> isvalid: 
<span class="token boolean">true</span>
baseOffset: <span class="token number">2</span> lastOffset: <span class="token number">2</span> count: <span class="token number">1</span> baseSequence: <span class="token parameter variable">-1</span> lastSequence: <span class="token parameter variable">-1</span> producerId: <span class="token parameter variable">-1</span> 
producerEpoch: <span class="token parameter variable">-1</span> partitionLeaderEpoch: <span class="token number">0</span> isTransactional: <span class="token boolean">false</span> isControl: <span class="token boolean">false</span> position: 
<span class="token number">75</span> CreateTime: <span class="token number">1636351749089</span> size: <span class="token number">77</span> magic: <span class="token number">2</span> compresscodec: none crc: <span class="token number">273943004</span> isvalid: 
<span class="token boolean">true</span>
baseOffset: <span class="token number">3</span> lastOffset: <span class="token number">3</span> count: <span class="token number">1</span> baseSequence: <span class="token parameter variable">-1</span> lastSequence: <span class="token parameter variable">-1</span> producerId: <span class="token parameter variable">-1</span> 
producerEpoch: <span class="token parameter variable">-1</span> partitionLeaderEpoch: <span class="token number">0</span> isTransactional: <span class="token boolean">false</span> isControl: <span class="token boolean">false</span> position: 
<span class="token number">152</span> CreateTime: <span class="token number">1636351749119</span> size: <span class="token number">77</span> magic: <span class="token number">2</span> compresscodec: none crc: <span class="token number">106207379</span> isvalid: 
<span class="token boolean">true</span>
baseOffset: <span class="token number">4</span> lastOffset: <span class="token number">8</span> count: <span class="token number">5</span> baseSequence: <span class="token parameter variable">-1</span> lastSequence: <span class="token parameter variable">-1</span> producerId: <span class="token parameter variable">-1</span> 
producerEpoch: <span class="token parameter variable">-1</span> partitionLeaderEpoch: <span class="token number">0</span> isTransactional: <span class="token boolean">false</span> isControl: <span class="token boolean">false</span> position: 
<span class="token number">229</span> CreateTime: <span class="token number">1636353061435</span> size: <span class="token number">141</span> magic: <span class="token number">2</span> compresscodec: none crc: <span class="token number">157376877</span> isvalid: 
<span class="token boolean">true</span>
baseOffset: <span class="token number">9</span> lastOffset: <span class="token number">13</span> count: <span class="token number">5</span> baseSequence: <span class="token parameter variable">-1</span> lastSequence: <span class="token parameter variable">-1</span> producerId: <span class="token parameter variable">-1</span> 
producerEpoch: <span class="token parameter variable">-1</span> partitionLeaderEpoch: <span class="token number">0</span> isTransactional: <span class="token boolean">false</span> isControl: <span class="token boolean">false</span> position: 
<span class="token number">370</span> CreateTime: <span class="token number">1636353204051</span> size: <span class="token number">146</span> magic: <span class="token number">2</span> compresscodec: none crc: <span class="token number">4058582827</span> isvalid: 
<span class="token boolean">true</span>
</code></pre></div><ol start="3"><li><strong>index文件和log文件详解</strong></li></ol><p><img src="`+G+'" alt="34"></p><p>说明：日志存储参数配置</p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>log.segment.bytes</td><td>Kafka 中 log 日志是分成一块块存储的，此配置是指 log 日志划分<br>成块的大小，默认值 1G。</td></tr><tr><td>log.index.interval.bytes</td><td>默认 4kb，kafka 里面每当写入了 4kb 大小的日志（.log），<br>然后就往 index 文件里面记录一个索引。 稀疏索引。</td></tr></tbody></table><h5 id="_4-4-2-文件清理策略" tabindex="-1"><a class="header-anchor" href="#_4-4-2-文件清理策略" aria-hidden="true">#</a> 4.4.2 文件清理策略</h5><p>Kafka 中默认的日志保存时间为 7 天，可以通过调整如下参数修改保存时间。</p><ul><li>Log.retention.hours，最低优先级小时，默认7天。</li><li>log.retention.minutes，分钟。</li><li>log.retention.ms，最高优先级毫秒。</li><li>log.retention.check.interval.ms，负责设置检查周期，默认 5 分钟。</li></ul><p>那么日志一旦超过了设置的时间，怎么处理呢？</p><p>Kafka 中提供的日志清理策略有 delete 和 compact 两种。</p><ol><li><strong>delete 日志阐述：将过期数据删除</strong></li></ol><ul><li>log.cleanup.policy = delete 所有数据启用阐述策略</li></ul><p>(1) 基于时间：默认打开。以 segment 中所有记录中的最大时间戳作为该文件时间戳。</p><p>(2) 基于大小：默认关闭。超过设置的所有日志总大小，阐述最早的 segment 。</p><p>log.retention.bytes，默认等于-1，表示无穷大。</p><p>**思考：**如果一个 segment 中有一部分数据过期，一部分没有过期，怎么处理？</p><p><img src="'+D+'" alt="35"></p><ol start="2"><li><strong>compact 日志压缩</strong></li></ol><p>compact日志压缩：对于相同 key 的不同 value 值，值保留最后一个版本。</p><ul><li>log.cleanup.policy = compact所有数据启动压缩策略</li></ul><p><img src="'+M+'" alt="36"></p><p>压缩后的offset可能是不连续的，比如上图中没有6，当从这些offset消费消息时，将会拿到比这个 offset 大的 offset 对应的消息，实际上会拿到 offset 为 7 的消息，并从这个位置开始消费。</p><p>​ 这种策略只适合特殊场景，比如消息的 key 是用户 ID，value 是用户的资料，通过这种压缩策略，整个消息集里就保存了所有用户最新的资料。</p><h4 id="_4-5-高效读写数据" tabindex="-1"><a class="header-anchor" href="#_4-5-高效读写数据" aria-hidden="true">#</a> 4.5 高效读写数据</h4><ol><li><p>Kafka 本身是分布式集群，可以采用分区技术，并行高度。</p></li><li><p>读数据采用稀疏索引，可以快速定位要消费的数据</p></li><li><p>顺序写磁盘</p><p>kafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到 600M/s，而随机写只有 100 k/s。这与磁盘的机械机构有关，顺序写之所以快，是因为为其省去了大量磁头寻址的时间。</p></li></ol><p><img src="'+V+'" alt="37"></p><ol start="4"><li><strong>页缓存</strong> <strong>+</strong> <strong>零拷贝技术</strong></li></ol><p><strong>零拷贝</strong>：Kafka 的数据加工处理操作交由 Kafka 生产者和 Kafka 消费者处理。Kafka Broker 应用层不关系存储的数据，所以就不用走应用层，传输效率高。</p><p><strong>PageCache页缓存</strong>：Kafka 重度依赖底层操作系统提供的 PageCache 功能。当上层有写操作时，操作系统只是将数据写入 PageCache。当读操作发生时，先从PageCache中查找，如果找不到，再去聪攀中读取。实际上 PageCache 是把尽可能多的空闲内存都当做了磁盘缓存来使用。</p><p><img src="'+B+'" alt="38"></p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>log.flush.interval.messages</td><td>强制页缓存刷写到磁盘的条数，默认是 long 的最大值，<br>9223372036854775807。一般不建议修改，交给系统自己管<br>理。</td></tr><tr><td>log.flush.interval.ms</td><td>每隔多久，刷数据到磁盘，默认是 null。一般不建议修改，<br>交给系统自己管理。</td></tr></tbody></table><h3 id="五、kafka-消费者" tabindex="-1"><a class="header-anchor" href="#五、kafka-消费者" aria-hidden="true">#</a> 五、Kafka 消费者</h3><h4 id="_5-1-kafka-消费方式" tabindex="-1"><a class="header-anchor" href="#_5-1-kafka-消费方式" aria-hidden="true">#</a> 5.1 Kafka 消费方式</h4><ul><li><strong>pull（拉）模式</strong>：consumer 采用从 broker 中主动拉去数据。Kafka 采用这种方式。</li><li><strong>push（推）模式</strong>：Kafka没有采用这种方式，因为由 broker 决定消息发送速率，很难适应所有消费者的消费速率。例如推送的速度是 50m/s，Consumer1，Consumer2就来不及处理消息。</li></ul><p>pull 模式不足之处是，如果Kafka 没有数据，消费者可能会陷入循环中，一直返回空数据。</p><p><img src="'+Z+'" alt="39"></p><h4 id="_5-2-kafka-消费者工作流程" tabindex="-1"><a class="header-anchor" href="#_5-2-kafka-消费者工作流程" aria-hidden="true">#</a> 5.2 Kafka 消费者工作流程</h4><h5 id="_5-2-1-消费者总体工作流程" tabindex="-1"><a class="header-anchor" href="#_5-2-1-消费者总体工作流程" aria-hidden="true">#</a> 5.2.1 消费者总体工作流程</h5><p><img src="'+H+'" alt="40"></p><h5 id="_5-2-2-消费者组原理" tabindex="-1"><a class="header-anchor" href="#_5-2-2-消费者组原理" aria-hidden="true">#</a> 5.2.2 消费者组原理</h5><p><strong>Consumer Group （CG）</strong>：消费者组，由多个consumer组成。形成一个消费者组的条件，是所有消费者的 groupid 相同。</p><ul><li>消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费。</li><li>消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</li></ul><p><img src="'+X+'" alt="41"></p><p><img src="'+U+'" alt="42"></p><p>1、<strong>coordinator：辅助实现消费者组的初始化和分区的分配。</strong></p><p>coordinator节点选择 = groupid的hashcode值 % 50（ __consumer_offsets的分区数量）</p><p>例如： groupid的hashcode值 = 1，1% 50 = 1，那么__consumer_offsets 主题的1号分区，在哪个broker上，就选择这个节点的coordinator 作为这个消费者组的老大。消费者组下的所有的消费者提交offset的时候就往这个分区去提交offset。</p><ol><li><p>每个consumer都发送JoinGroup请求</p></li><li><p>选出一个 consumer 作为 leader。</p></li><li><p>把要消费的 topic 情况发送给 leader 消费者</p></li><li><p>leader会负责制定消费方案</p></li><li><p>把消费方案发给coordinator。</p></li><li><p>Coordinator就把消费方案下发给各个consumer。</p></li><li><p>每个消费者都会和coordinator保持心跳（默认3s），一旦超时（session.timeout.ms=45s），该消费者会被移除，并触发再平衡；</p><p>或者消费者处理消息的时间过长（max.poll.interval.ms5分钟），也会触发再平衡。</p></li></ol><p><img src="'+Y+'" alt="43"></p><p><img src="'+Q+'" alt="44"></p><h5 id="_5-2-3-消费者重要参数" tabindex="-1"><a class="header-anchor" href="#_5-2-3-消费者重要参数" aria-hidden="true">#</a> 5.2.3 消费者重要参数</h5><table><thead><tr><th>参数名称</th><th>描述</th></tr></thead><tbody><tr><td>bootstrap.servers</td><td>向 Kafka 集群建立初始连接用到的 host/port 列表。</td></tr><tr><td>key.deserializer 和value.deserializer</td><td>指定接收消息的 key 和 value 的反序列化类型。一定要写全类名。</td></tr><tr><td>group.id</td><td>标记消费者所属的消费者组。</td></tr><tr><td>enable.auto.commit</td><td>默认值为 true，消费者会自动周期性地向服务器提交偏移量。</td></tr><tr><td>auto.commit.interval.ms</td><td>如果设置了 enable.auto.commit 的值为 true， 则该值定义了<br>消费者偏移量向 Kafka 提交的频率，默认 5s。</td></tr><tr><td>auto.offset.reset</td><td>当 Kafka 中没有初始偏移量或当前偏移量在服务器中不存在<br>（如，数据被删除了），该如何处理？ earliest：自动重置偏<br>移量到最早的偏移量。 latest：默认，自动重置偏移量为最<br>新的偏移量。 none：如果消费组原来的（previous）偏移量<br>不存在，则向消费者抛异常。 anything：向消费者抛异常。</td></tr><tr><td>offsets.topic.num.partitions</td><td>__consumer_offsets 的分区数，默认是 50 个分区。</td></tr><tr><td>heartbeat.interval.ms</td><td>Kafka 消费者和 coordinator 之间的心跳时间，默认 3s。<br>该条目的值必须小于 session.timeout.ms ，也不应该高于<br>session.timeout.ms 的 1/3。</td></tr><tr><td>session.timeout.ms</td><td>Kafka 消费者和 coordinator 之间连接超时时间，默认 45s。<br>超过该值，该消费者被移除，消费者组执行再平衡。</td></tr><tr><td>max.poll.interval.ms</td><td>消费者处理消息的最大时长，默认是 5 分钟。超过该值，该<br>消费者被移除，消费者组执行再平衡。</td></tr><tr><td>fetch.min.bytes</td><td>默认 1 个字节。消费者获取服务器端一批消息最小的字节数。</td></tr><tr><td>fetch.max.wait.ms</td><td>默认 500ms。如果没有从服务器端获取到一批数据的最小字<br>节数。该时间到，仍然会返回数据。</td></tr><tr><td>fetch.max.bytes</td><td>默认 Default: 52428800（50 m）。消费者获取服务器端一批<br>消息最大的字节数。如果服务器端一批次的数据大于该值<br>（50m）仍然可以拉取回来这批数据，因此，这不是一个绝<br>对最大值。一批次的大小受 message.max.bytes （broker <br>config）or max.message.bytes （topic config）影响。</td></tr><tr><td>max.poll.records</td><td>一次 poll 拉取数据返回消息的最大条数，默认是 500 条。</td></tr></tbody></table><h4 id="_5-3-消费者-api" tabindex="-1"><a class="header-anchor" href="#_5-3-消费者-api" aria-hidden="true">#</a> 5.3 消费者 API</h4><h5 id="_5-3-1-独立消费者案例-订阅主题" tabindex="-1"><a class="header-anchor" href="#_5-3-1-独立消费者案例-订阅主题" aria-hidden="true">#</a> 5.3.1 独立消费者案例（订阅主题）</h5><ul><li><p>需求：</p><p>创建一个独立消费者，消费 first 主题中数据。</p></li></ul><p><img src="'+W+`" alt="45"></p><p>【注意】：消费者 API 代码中必须配置消费者组 id。命令行启动消费者不填写消费者组 id 会被自动填写随机的消费者组 id。</p><ul><li>实现步骤 <ol><li>创建包名：com.yooome.kafka.consumer</li><li>编写代码</li></ol></li></ul><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerConfig</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecord</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecords</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">KafkaConsumer</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">KafkaProducer</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">ProducerConfig</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">ProducerRecord</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringDeserializer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>time<span class="token punctuation">.</span></span><span class="token class-name">Duration</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">ArrayList</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomConsumer</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建kafka生产者配置对象</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// key,value 序列化（必须）：key.serializer，value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">GROUP_ID_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;test&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3. 创建 kafka 生产者对象</span>
        <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaConsumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> topic <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        topic<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        kafkaConsumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 拉去数据打印</span>
        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumerRecords <span class="token operator">=</span> kafkaConsumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumerRecord <span class="token operator">:</span> consumerRecords<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;consumerRecord: &quot;</span> <span class="token operator">+</span> consumerRecord<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>测试：</p><ol><li>在IDEA 中执行消费者程序。</li><li>在Kafka集群控制台，创建 Kafka 生产者，并输入数据。</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-console-producer.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--topic</span> first
<span class="token operator">&gt;</span>hello
</code></pre></div><ol start="3"><li>IDEA 控制台接受到的信息</li></ol><div class="language-json" data-ext="json"><pre class="language-json"><code>consumerRecord<span class="token operator">:</span> ConsumerRecord(topic = first<span class="token punctuation">,</span> partition = <span class="token number">0</span><span class="token punctuation">,</span> leaderEpoch = <span class="token number">0</span><span class="token punctuation">,</span> offset = <span class="token number">79</span><span class="token punctuation">,</span> CreateTime = <span class="token number">1645702655382</span><span class="token punctuation">,</span> serialized key size = <span class="token number">-1</span><span class="token punctuation">,</span> serialized value size = <span class="token number">4</span><span class="token punctuation">,</span> headers = RecordHeaders(headers = <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> isReadOnly = <span class="token boolean">false</span>)<span class="token punctuation">,</span> key = <span class="token null keyword">null</span><span class="token punctuation">,</span> value = asga)
</code></pre></div><h5 id="_5-3-2-独立消费者案例-订阅分区" tabindex="-1"><a class="header-anchor" href="#_5-3-2-独立消费者案例-订阅分区" aria-hidden="true">#</a> 5.3.2 独立消费者案例（订阅分区）</h5><ol><li><strong>需求</strong>：创建一个独立消费者，消费 first 主题 0 号分区的数据。</li></ol><p><img src="`+J+`" alt="46"></p><ol start="2"><li>实现步骤</li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerConfig</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecord</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecords</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">KafkaConsumer</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span></span><span class="token class-name">TopicPartition</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringDeserializer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>time<span class="token punctuation">.</span></span><span class="token class-name">Duration</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">ArrayList</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomConsumerPartition</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建kafka生产者配置对象</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// key,value 序列化（必须）：key.serializer，value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">GROUP_ID_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;test&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3. 创建 kafka 生产者对象</span>
        <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaConsumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">&gt;</span></span> topicPartitions <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        topicPartitions<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        kafkaConsumer<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span>topicPartitions<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 拉去数据打印</span>
        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumerRecords <span class="token operator">=</span> kafkaConsumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumerRecord <span class="token operator">:</span> consumerRecords<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;consumerRecord: &quot;</span> <span class="token operator">+</span> consumerRecord<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><p>测试：</p><ol><li><p>在IDEA中执行消费者程序。</p></li><li><p>在IDEA中执行消费者程序 CustomProducerCallback()在控制台观察生成几个 0 号 分区的数据</p></li></ol><div class="language-json" data-ext="json"><pre class="language-json"><code>consumerRecord<span class="token operator">:</span> ConsumerRecord(topic = first<span class="token punctuation">,</span> partition = <span class="token number">0</span><span class="token punctuation">,</span> leaderEpoch = <span class="token number">0</span><span class="token punctuation">,</span> offset = <span class="token number">88</span><span class="token punctuation">,</span> CreateTime = <span class="token number">1645703441423</span><span class="token punctuation">,</span> serialized key size = <span class="token number">-1</span><span class="token punctuation">,</span> serialized value size = <span class="token number">7</span><span class="token punctuation">,</span> headers = RecordHeaders(headers = <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> isReadOnly = <span class="token boolean">false</span>)<span class="token punctuation">,</span> key = <span class="token null keyword">null</span><span class="token punctuation">,</span> value = yooome3)
</code></pre></div><h5 id="_5-3-3-消费者组案例" tabindex="-1"><a class="header-anchor" href="#_5-3-3-消费者组案例" aria-hidden="true">#</a> 5.3.3 消费者组案例</h5><ol><li><strong>需求</strong>：测试同一个主题的分区数据，只能由一个消费者组中的一个消费。</li></ol><p><img src="`+nn+`" alt="47"></p><ol start="2"><li><p>案例实操</p><p>(1) 复制一份基础消费者的代码，在IDEA 中同时启动，即可启动同一个消费者组中的两个消费者。</p></li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerConfig</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecord</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecords</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">KafkaConsumer</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">KafkaProducer</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">ProducerConfig</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">ProducerRecord</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringDeserializer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>time<span class="token punctuation">.</span></span><span class="token class-name">Duration</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">ArrayList</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomConsumer</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建kafka生产者配置对象</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// key,value 序列化（必须）：key.serializer，value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">GROUP_ID_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;test&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3. 创建 kafka 生产者对象</span>
        <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaConsumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> topic <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        topic<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        kafkaConsumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 拉去数据打印</span>
        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumerRecords <span class="token operator">=</span> kafkaConsumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumerRecord <span class="token operator">:</span> consumerRecords<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;consumerRecord: &quot;</span> <span class="token operator">+</span> consumerRecord<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><p>​ (2) 启动代码中的生产者发送消息，在IDEA控制台即可看到两个消费者在消费不同分区的数据（如果只发生到一个分区，可以在发送时增加延迟代码 Thread.sleep(2)😉</p><div class="language-json" data-ext="json"><pre class="language-json"><code>ConsumerRecord(topic = first<span class="token punctuation">,</span> partition = <span class="token number">0</span><span class="token punctuation">,</span> leaderEpoch = <span class="token number">2</span><span class="token punctuation">,</span> offset = <span class="token number">3</span><span class="token punctuation">,</span> CreateTime = <span class="token number">1629169606820</span><span class="token punctuation">,</span> serialized key size = <span class="token number">-1</span><span class="token punctuation">,</span> serialized value size = <span class="token number">8</span><span class="token punctuation">,</span> headers = RecordHeaders(headers = <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> isReadOnly = <span class="token boolean">false</span>)<span class="token punctuation">,</span> key = <span class="token null keyword">null</span><span class="token punctuation">,</span> value = hello1)

ConsumerRecord(topic = first<span class="token punctuation">,</span> partition = <span class="token number">1</span><span class="token punctuation">,</span> leaderEpoch = <span class="token number">3</span><span class="token punctuation">,</span> offset = <span class="token number">2</span><span class="token punctuation">,</span> CreateTime = <span class="token number">1629169609524</span><span class="token punctuation">,</span> serialized key size = <span class="token number">-1</span><span class="token punctuation">,</span> serialized value size = <span class="token number">6</span><span class="token punctuation">,</span> headers = RecordHeaders(headers = <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> isReadOnly = <span class="token boolean">false</span>)<span class="token punctuation">,</span> key = <span class="token null keyword">null</span><span class="token punctuation">,</span> value = hello2)

ConsumerRecord(topic = first<span class="token punctuation">,</span> partition = <span class="token number">2</span><span class="token punctuation">,</span> leaderEpoch = <span class="token number">3</span><span class="token punctuation">,</span> offset = <span class="token number">21</span><span class="token punctuation">,</span> CreateTime = <span class="token number">1629169611884</span><span class="token punctuation">,</span> serialized key size = <span class="token number">-1</span><span class="token punctuation">,</span> serialized value size = <span class="token number">6</span><span class="token punctuation">,</span> headers = RecordHeaders(headers = <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> isReadOnly = <span class="token boolean">false</span>)<span class="token punctuation">,</span> key = <span class="token null keyword">null</span><span class="token punctuation">,</span> value = hello3)
</code></pre></div><p>​ (3) 重新发送到一个全新的主题中，由于默认创建的主题分区数为 1，可以看到只能有一个消费者消费到数据。</p><p><img src="`+sn+'" alt="48"></p><h4 id="_5-4-生产经验-分区的分配以及再平衡" tabindex="-1"><a class="header-anchor" href="#_5-4-生产经验-分区的分配以及再平衡" aria-hidden="true">#</a> 5.4 生产经验---分区的分配以及再平衡</h4><p>1、 一个consumer group 中有多个 consumer 组成， 一个 topic 有多个 partition 组成，现在的问题是，到底由哪个 consumer 来消费哪个 partition 的数据。</p><p>2、 Kafka 有四种主流的分区分配策略：Range、RoundRobin、Sticky、CooperativeSticky。可以通过配置参数 partition.assignment.strategy，修改分区的分配策略。默认策略是 Range+ CooperativeSticky。Kafka 可以同时使用多个分区分配策略。</p><p><img src="'+an+'" alt="49"></p><table><thead><tr><th>参数名称</th><th>描述</th></tr></thead><tbody><tr><td>heartbeat.interval.ms</td><td>Kafka 消费者和 coordinator 之间的心跳时间，默认 3s。<br>该条目的值必须小于 session.timeout.ms，也不应该高于<br>session.timeout.ms 的 1/3。</td></tr><tr><td>session.timeout.ms</td><td>Kafka 消费者和 coordinator 之间连接超时时间，默认 45s。超<br>过该值，该消费者被移除，消费者组执行再平衡。</td></tr><tr><td>max.poll.interval.ms</td><td>消费者处理消息的最大时长，默认是 5 分钟。超过该值，该<br>消费者被移除，消费者组执行再平衡。</td></tr><tr><td>partition.assignment.strategy</td><td>消 费 者 分 区 分 配 策 略 ， 默 认 策 略 是 Range +CooperativeSticky。Kafka 可以同时使用多个分区分配策略。可 以 选 择 的 策 略 包 括 ： Range 、 RoundRobin 、 Sticky 、CooperativeSticky</td></tr></tbody></table><h5 id="_5-4-1-range-以及再平衡" tabindex="-1"><a class="header-anchor" href="#_5-4-1-range-以及再平衡" aria-hidden="true">#</a> 5.4.1 Range 以及再平衡</h5><ol><li><strong>Range 是对每个 topic 而言的</strong>。</li></ol><p>​ 首先对同一个 topic 里面的分区按照序号进行排序，并对消费者按照字母顺序进行 排序。</p><p>假如现在有 7 个分区， 3 个消费者，排序后的分区将会是 0,1,2,3,4,5,6；消费者排序完成之后将会是 C0,C1,C2。</p><p>通过 partitions数/consumer数 来决定每个消费者应该消费几个分区。如果除不尽，那么前面几个消费者将会多消费 1 个分区。</p><p>例如，7/3 = 2 余 1 ，除不尽，那么 消费者 C0 便会多消费 1 个分区。 8/3=2余2，除不尽，那么C0和C1分别多消费一个。</p><p><strong>注意</strong>：如果只是针对 1 个 topic 而言，C0消费者多消费1个分区影响不是很大。但是如果有 N 多个 topic，那么针对每个 topic，消费者C0都将多消费 1 个分区，topic越多，C0消 费的分区会比其他消费者明显多消费 N 个分区。</p><p>容易产生数据倾斜！</p><p><img src="'+tn+`" alt="50"></p><ol start="2"><li><strong>Range分区分配策略案例</strong></li></ol><ul><li>①修改主题 first 为 7 个分区</li></ul><div class="language-json" data-ext="json"><pre class="language-json"><code><span class="token punctuation">[</span>atguigu@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server 
hadoop102<span class="token operator">:</span><span class="token number">9092</span> --alter --topic first --partitions <span class="token number">7</span>
</code></pre></div><p>【注意】分区数可以增加，但是不能减少。</p><ul><li>② 复制CustomConsuer类，创建 CustomConsumer2。这样可以由三个消费者 CustomConsumer、CustomConsumer1、CustomConsumer2 组成消费者组，组名都为“test”，同时启动 3 个消费者。</li></ul><p><img src="`+pn+`" alt="51"></p><ul><li>③ 启动CustomProducer生产者，发送 500 条消息，随机发送到不同的分区</li></ul><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">KafkaProducer</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">ProducerConfig</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">ProducerRecord</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomProducer</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span>
            <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span>
                <span class="token string">&quot;hadoop102:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span>
                <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span>
                <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaProducer <span class="token operator">=</span> <span class="token keyword">new</span>
                <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">7</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            kafkaProducer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">,</span> i<span class="token punctuation">,</span>
                    <span class="token string">&quot;test&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;atguigu&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        kafkaProducer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>说明：Kafka 默认的分区分配策略就是 Range + CooperativeSticky，所以不需要修改策略。</p><ul><li>④ 观看 3 个消费者分别消费哪些分区的数据。</li></ul><p><img src="`+on+'" alt="52"></p><p><img src="'+en+'" alt="53"></p><p><img src="'+cn+'" alt="54"></p><ol start="3"><li><strong>Range 分区分配再平衡案例</strong></li></ol><p>（1）<strong>停止掉 0 号消费者，快速重新发送消息观看结果（45s 以内，越快越好）</strong>。</p><p>​ 1 号消费者：消费到 3、4 号分区数据。</p><p>​ 2 号消费者：消费到 5、6 号分区数据。</p><p>0 号消费者的任务会整体被分配到 1 号消费者或者 2 号消费者。</p><p><strong>说明</strong>：0 号消费者挂掉后，消费者组需要按照超时时间 45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他 broker 执行。</p><p>（2）<strong>再次重新发送消息观看结果（45s 以后）。</strong></p><p>​ 1 号消费者：消费到 0、1、2、3 号分区数据。</p><p>​ 2 号消费者：消费到 4、5、6 号分区数据。</p><p><strong>说明</strong>：消费者 0 已经被踢出消费者组，所以重新按照 range 方式分配。</p><h5 id="_5-4-2-roundrobin-以及再平衡" tabindex="-1"><a class="header-anchor" href="#_5-4-2-roundrobin-以及再平衡" aria-hidden="true">#</a> 5.4.2 RoundRobin 以及再平衡</h5><ol><li><strong>RoundRobin分区策略原理</strong></li></ol><p>RoundRobin 针对集群中 所有 Topic 而言。</p><p>RoundRobin 轮询分区策略，是把所有的 partition 和所有的 consumer 都列出来，然后按照 hashcode 进行排序，最后通过轮询算法来分配 partition 给到各个消费者。</p><p><img src="'+ln+`" alt="55"></p><ol start="2"><li><strong>RoundRobin 分区分配策略案例</strong></li></ol><p>（1）依次在 CustomConsumer、CustomConsumer1、CustomConsumer2 三个消费者代码中修改分区分配策略为 RoundRobin。</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token comment">// 修改分区分配策略</span>
properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">PARTITION_ASSIGNMENT_STRATEGY_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;org.apache.kafka.clients.consumer.RoundRobinAssignor&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><p>（2）重启 3 个消费者，重复发送消息的步骤，观看分区结果。</p><p><img src="`+un+'" alt="56"></p><p><img src="'+kn+'" alt="57"></p><p><img src="'+rn+`" alt="58"></p><ol start="3"><li><strong>RoundRobin 分区分配在平衡案例</strong></li></ol><p>（1）停止掉 0 号消费者，快速重新发送消息观看结果（45s 以内，越快越好）。</p><p>​ 1 号消费者：消费到 2、5 号分区数据</p><p>​ 2 号消费者：消费到 4、1 号分区数据</p><p>​ 0 号消费者的任务会按照 RoundRobin 的方式，把数据轮询分成 0 、6 和 3 号分区数据，</p><p>分别由 1 号消费者或者 2 号消费者消费。</p><p><strong>说明</strong>：0 号消费者挂掉后，消费者组需要按照超时时间 45s 来判断它是否退出，所以需</p><p>要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他 broker 执行。</p><p>（2）再次重新发送消息观看结果（45s 以后）。</p><p>​ 1 号消费者：消费到 0、2、4、6 号分区数据</p><p>​ 2 号消费者：消费到 1、3、5 号分区数据</p><p><strong>说明</strong>：消费者 0 已经被踢出消费者组，所以重新按照 RoundRobin 方式分配。</p><h5 id="_5-4-3-sticky-以及在平衡" tabindex="-1"><a class="header-anchor" href="#_5-4-3-sticky-以及在平衡" aria-hidden="true">#</a> 5.4.3 Sticky 以及在平衡</h5><p>**粘性分区定义：**可以理解为分配的结果带有“粘性的”。即在执行一次新的分配之前，考虑上一次分配的结果，尽量少的调整分配的变动，可以节省大量的开销。粘性分区是 Kafka 从 0.11.x 版本开始引入这种分配策略，首先会尽量均衡的放置分区到消费者上面，在出现同一消费者组内消费者出现问题的时候，会尽量保持原有分配的分区不变化。</p><p>1）需求：</p><p>设置主题为 first，7 个分区；准备 3 个消费者，采用粘性分区策略，并进行消费，观察消费分配情况。然后再停止其中一个消费者，再次观察消费分配情况。</p><p>2）步骤：</p><p>（1）修改分区分配策略为粘性。</p><p>注意：3 个消费者都应该注释掉，之后重启 3 个消费者，如果出现报错，全部停止等会再重启，或者修改为全新的消费者组。</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token comment">// 修改分区分配策略</span>
<span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> startegys <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
startegys<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">&quot;org.apache.kafka.clients.consumer.StickyAssignor&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">PARTITION_ASSIGNMENT_STRATEGY_CONFIG</span><span class="token punctuation">,</span> startegys<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><p>（2）使用同样的生产者发送 500 条消息。</p><p>可以看到会尽量保持分区的个数近似划分分区。</p><p><img src="`+dn+'" alt="59"></p><p><img src="'+mn+'" alt="60"></p><p><strong>3）Sticky分区分配再平衡案例</strong></p><p>（1）停止掉 0 号消费者，快速重新发送消息观看结果（45s 以内，越快越好）。</p><p>​ 1 号消费者：消费到 2、5、3 号分区数据。</p><p>​ 2 号消费者：消费到 4、6 号分区数据。</p><p>​ 0 号消费者的任务会按照粘性规则，尽可能均衡的随机分成 0 和 1 号分区数据，分别</p><p>由 1 号消费者或者 2 号消费者消费。</p><p><strong>说明</strong>：0 号消费者挂掉后，消费者组需要按照超时时间 45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他 broker 执行。</p><p>（2）再次重新发送消息观看结果（45s 以后）。</p><p>​ 1 号消费者：消费到 2、3、5 号分区数据。</p><p>​ 2 号消费者：消费到 0、1、4、6 号分区数据。</p><p><strong>说明</strong>：消费者 0 已经被踢出消费者组，所以重新按照粘性方式分配。</p><h4 id="_5-5-offset-位移" tabindex="-1"><a class="header-anchor" href="#_5-5-offset-位移" aria-hidden="true">#</a> 5.5 offset 位移</h4><h5 id="_5-5-1-offset-的默认维护位置" tabindex="-1"><a class="header-anchor" href="#_5-5-1-offset-的默认维护位置" aria-hidden="true">#</a> 5.5.1 offset 的默认维护位置</h5><p><img src="'+gn+`" alt="61"></p><p>__consumer_offsets 主题里面采用 key 和 value 的方式存储数据。key 是 group.id+topic+分区号，value 就是当前 offset 的值。每隔一段时间，kafka 内部会对这个 topic 进行compact，也就是每个 group.id+topic+分区号就保留最新数据。</p><p><strong>1）消费 offset 案例</strong></p><p>（0）思想：__consumer_offsets 为 Kafka 中的 topic，那就可以通过消费者进行消费。</p><p>（1）在配置文件 config/consumer.properties 中添加配置 exclude.internal.topics=false，</p><p>默认是 true，表示不能消费系统主题。为了查看该系统主题数据，所以该参数修改为 false。</p><p>（2）采用命令行方式，创建一个新的 topic。</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>topics<span class="token punctuation">.</span>sh <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server 
hadoop102<span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>create <span class="token operator">--</span>topic atguigu <span class="token operator">--</span>partitions <span class="token number">2</span> <span class="token operator">--</span>replication<span class="token operator">-</span>factor <span class="token number">2</span>
</code></pre></div><p>（3）启动生产者往 atguigu 生产数据。</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>producer<span class="token punctuation">.</span>sh <span class="token operator">--</span>topic atguigu <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server hadoop102<span class="token operator">:</span><span class="token number">9092</span>
</code></pre></div><p>（4）启动消费者消费 atguigu 数据。</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop104</span> kafka<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>consumer<span class="token punctuation">.</span>sh <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server hadoop102<span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>topic atguigu <span class="token operator">--</span>group test
</code></pre></div><p>注意：指定消费者组名称，更好观察数据存储位置（key 是 group.id+topic+分区号）。</p><p>（5）查看消费者消费主题__consumer_offsets。</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>consumer<span class="token punctuation">.</span>sh <span class="token operator">--</span>topic 
__consumer_offsets <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server hadoop102<span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>consumer<span class="token punctuation">.</span>config config<span class="token operator">/</span>consumer<span class="token punctuation">.</span>properties <span class="token operator">--</span>formatter 
<span class="token string">&quot;kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter&quot;</span> <span class="token operator">--</span>from<span class="token operator">-</span>beginning
  
<span class="token punctuation">[</span>offset<span class="token punctuation">,</span>atguigu<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">::</span><span class="token class-name">OffsetAndMetadata</span><span class="token punctuation">(</span>offset<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> 
leaderEpoch<span class="token operator">=</span><span class="token class-name">Optional</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">,</span> commitTimestamp<span class="token operator">=</span><span class="token number">1622442520203</span><span class="token punctuation">,</span> expireTimestamp<span class="token operator">=</span><span class="token class-name">None</span><span class="token punctuation">)</span>
  
<span class="token punctuation">[</span>offset<span class="token punctuation">,</span>atguigu<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">::</span><span class="token class-name">OffsetAndMetadata</span><span class="token punctuation">(</span>offset<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> leaderEpoch<span class="token operator">=</span><span class="token class-name">Optional</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">,</span>commitTimestamp<span class="token operator">=</span><span class="token number">1622442520203</span><span class="token punctuation">,</span> expireTimestamp<span class="token operator">=</span><span class="token class-name">None</span><span class="token punctuation">)</span>
</code></pre></div><h5 id="_5-5-2-自动提交offset" tabindex="-1"><a class="header-anchor" href="#_5-5-2-自动提交offset" aria-hidden="true">#</a> 5.5.2 自动提交offset</h5><p>为了使我们能够专注于自己的业务逻辑，Kafka提供了自动提交offset的功能。</p><p>自动提交offset的相关参数：</p><ul><li><p><strong>enable.auto.commit</strong>：是否开启自动提交offset功能，默认是true</p></li><li><p><strong>auto.commit.interval.ms</strong>：自动提交offset的时间间隔，默认是5s</p></li></ul><p><img src="`+fn+`" alt="62"></p><table><thead><tr><th>参数名称</th><th>描述</th></tr></thead><tbody><tr><td>enable.auto.commit</td><td>默认值为 true，消费者会自动周期性地向服务器提交偏移量。</td></tr><tr><td>auto.commit.interval.ms</td><td>如果设置了 enable.auto.commit 的值为 true， 则该值定义了消费者偏移量向 Kafka 提交的频率，默认 5s。</td></tr></tbody></table><ol><li><strong>消费者自动提交offset</strong></li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>consumer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerConfig</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecord</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecords</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">KafkaConsumer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Arrays</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomConsumerAutoOffset</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建 kafka 消费者配置类</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 添加配置参数</span>
        <span class="token comment">// 添加连接</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span>
                <span class="token string">&quot;hadoop102:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 配置序列化 必须</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span>
                <span class="token string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span>
                <span class="token string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 配置消费者组</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">GROUP_ID_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;test&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 是否自动提交 offset</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">ENABLE_AUTO_COMMIT_CONFIG</span><span class="token punctuation">,</span>
                <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 提交 offset 的时间周期 1000ms，默认 5s</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">AUTO_COMMIT_INTERVAL_MS_CONFIG</span><span class="token punctuation">,</span>
                <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//3. 创建 kafka 消费者</span>
        <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span>
                <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//4. 设置消费主题 形参是列表</span>
        consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//5. 消费数据</span>
        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 读取消息</span>
            <span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumerRecords <span class="token operator">=</span>
                    consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 输出消息</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumerRecord <span class="token operator">:</span>
                    consumerRecords<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>consumerRecord<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><h5 id="_5-5-3-手动提交offset" tabindex="-1"><a class="header-anchor" href="#_5-5-3-手动提交offset" aria-hidden="true">#</a> 5.5.3 手动提交offset</h5><p>虽然自动提交offset十分简单比那里，但由于其是基于时间提交的，开发人员难以把握 offset 提交的时机。一次 Kafka 还提供了手动提交 offset 的API。</p><p>手动提交 offset 的方法有两种：分别是 commitSync(同步提交)和commitAsync(异步提交)。两者的相同点是，都会将本次提交的一批数据最高的偏移量提交；不同点是，同步提交阻塞当前线程，一直到提交成功，并且会自动失败重试（由不可控因素导致，也会出现提交失败）；而异步提交则没有失败重试机制，故有可能提交失败。</p><ul><li><strong>commitSync（同步提交）</strong>：必须等待offset提交完毕，再去消费下一批数据。</li><li><strong>commitAsync（异步提交）</strong> ：发送完提交offset请求后，就开始消费下一批数据了。</li></ul><p>![截屏 1](./images/截屏 1.png)</p><p><strong>1）同步提交 offset</strong></p><p>由于同步提交 offset 有失败重试机制，故更加可靠，但是由于一直等待提交结果，提交的效率比较低。以下为同步提交 offset 的示例。</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerConfig</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecord</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecords</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">KafkaConsumer</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringDeserializer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>time<span class="token punctuation">.</span></span><span class="token class-name">Duration</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">ArrayList</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomConsumerByHandSync</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建kafka生产者配置对象</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// key,value 序列化（必须）：key.serializer，value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">GROUP_ID_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;test&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 是否自动提交 offset</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">ENABLE_AUTO_COMMIT_CONFIG</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 3. 创建 kafka 生产者对象</span>
        <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaConsumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> topic <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        topic<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        kafkaConsumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 拉去数据打印</span>
        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumerRecords <span class="token operator">=</span> kafkaConsumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumerRecord <span class="token operator">:</span> consumerRecords<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;consumerRecord: &quot;</span> <span class="token operator">+</span> consumerRecord<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
            <span class="token comment">// 同步提交 offset</span>
            kafkaConsumer<span class="token punctuation">.</span><span class="token function">commitSync</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p><strong>2）异步提交 offset</strong></p><p>虽然同步提交 offset 更可靠一些，但是由于其会阻塞当前线程，直到提交成功。因此吞吐量会受到很大的影响。因此更多的情况下，会选用异步提交 offset 的方式。以下为异步提交 offset 的示例：</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerConfig</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecord</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecords</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">KafkaConsumer</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringDeserializer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>time<span class="token punctuation">.</span></span><span class="token class-name">Duration</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">ArrayList</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomConsumerByHandSync</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建kafka生产者配置对象</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// key,value 序列化（必须）：key.serializer，value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">GROUP_ID_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;test&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 是否自动提交 offset</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">ENABLE_AUTO_COMMIT_CONFIG</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 3. 创建 kafka 生产者对象</span>
        <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaConsumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> topic <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        topic<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        kafkaConsumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 拉去数据打印</span>
        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumerRecords <span class="token operator">=</span> kafkaConsumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumerRecord <span class="token operator">:</span> consumerRecords<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;consumerRecord: &quot;</span> <span class="token operator">+</span> consumerRecord<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
            <span class="token comment">// 异步提交 offset</span>
            kafkaConsumer<span class="token punctuation">.</span><span class="token function">commitAsync</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><h5 id="_5-5-4-指定-offset-消费" tabindex="-1"><a class="header-anchor" href="#_5-5-4-指定-offset-消费" aria-hidden="true">#</a> <strong>5.5.4</strong> <strong>指定</strong> <strong>Offset</strong> <strong>消费</strong></h5><p>auto.offset.reset = earliest | latest | none 默认是 latest。</p><p>当 Kafka 中没有初始偏移量（消费者组第一次消费）或服务器上不再存在当前偏移量</p><p>时（例如该数据已被删除），该怎么办？</p><p>（1）earliest：自动将偏移量重置为最早的偏移量，--from-beginning。</p><p>（2）latest（默认值）：自动将偏移量重置为最新偏移量。</p><p>（3）none：如果未找到消费者组的先前偏移量，则向消费者抛出异常。</p><p><img src="`+bn+`" alt="63"></p><p>​ (4) 任意指定 offset 位移开始消费</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerConfig</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecord</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecords</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">KafkaConsumer</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span></span><span class="token class-name">TopicPartition</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringDeserializer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>time<span class="token punctuation">.</span></span><span class="token class-name">Duration</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">ArrayList</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">HashSet</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Set</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomConsumerSeek</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建kafka生产者配置对象</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// key,value 序列化（必须）：key.serializer，value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">GROUP_ID_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;test2&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3. 创建 kafka 生产者对象</span>
        <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaConsumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> topic <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        topic<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        kafkaConsumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">Set</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">&gt;</span></span> assignment<span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashSet</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">while</span> <span class="token punctuation">(</span>assignment<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            kafkaConsumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 获取消费者分区分配信息（有了分区分配信息才能开始消费）</span>
            assignment <span class="token operator">=</span> kafkaConsumer<span class="token punctuation">.</span><span class="token function">assignment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token comment">// 遍历所有分区，并指定 offset 从 1700 的位置开始消费</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">TopicPartition</span> tp<span class="token operator">:</span> assignment<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            kafkaConsumer<span class="token punctuation">.</span><span class="token function">seek</span><span class="token punctuation">(</span>tp<span class="token punctuation">,</span> <span class="token number">1700</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

        <span class="token comment">// 拉去数据打印</span>
        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumerRecords <span class="token operator">=</span> kafkaConsumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumerRecord <span class="token operator">:</span> consumerRecords<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;consumerRecord: &quot;</span> <span class="token operator">+</span> consumerRecord<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><p>【注意】：每次执行完，需要修改消费者组名；</p><h5 id="_5-5-5-指定时间消费" tabindex="-1"><a class="header-anchor" href="#_5-5-5-指定时间消费" aria-hidden="true">#</a> <strong>5.5.5</strong> <strong>指定时间消费</strong></h5><p>需求：在生产环境中，会遇到最近消费的几个小时数据异常，想重新按照时间消费。</p><p>例如要求按照时间消费前一天的数据，怎么处理？</p><p>操作步骤：</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>yooome<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token operator">*</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span></span><span class="token class-name">TopicPartition</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringDeserializer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>time<span class="token punctuation">.</span></span><span class="token class-name">Duration</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token operator">*</span></span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomConsumerSeek</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1. 创建kafka生产者配置对象</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// key,value 序列化（必须）：key.serializer，value.serializer</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">GROUP_ID_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;test2&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3. 创建 kafka 生产者对象</span>
        <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaConsumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> topic <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        topic<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">&quot;first&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        kafkaConsumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">Set</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">&gt;</span></span> assignment <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashSet</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">while</span> <span class="token punctuation">(</span>assignment<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            kafkaConsumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 获取消费者分区分配信息（有了分区分配信息才能开始消费）</span>
            assignment <span class="token operator">=</span> kafkaConsumer<span class="token punctuation">.</span><span class="token function">assignment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span></span> timestampToSearch <span class="token operator">=</span> <span class="token keyword">new</span>
                <span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 封装集合存储，每个分区对应一天前的数据</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">TopicPartition</span> topicPartition <span class="token operator">:</span> assignment<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            timestampToSearch<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>topicPartition<span class="token punctuation">,</span>
                    <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">currentTimeMillis</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">*</span> <span class="token number">24</span> <span class="token operator">*</span> <span class="token number">3600</span> <span class="token operator">*</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token comment">// 获取从 1 天前开始消费的每个分区的 offset</span>
        <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">OffsetAndTimestamp</span><span class="token punctuation">&gt;</span></span> offsets <span class="token operator">=</span>
                kafkaConsumer<span class="token punctuation">.</span><span class="token function">offsetsForTimes</span><span class="token punctuation">(</span>timestampToSearch<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 遍历每个分区，对每个分区设置消费时间。</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">TopicPartition</span> topicPartition <span class="token operator">:</span> assignment<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token class-name">OffsetAndTimestamp</span> offsetAndTimestamp <span class="token operator">=</span>
                    offsets<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>topicPartition<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 根据时间指定开始消费的位置</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>offsetAndTimestamp <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                kafkaConsumer<span class="token punctuation">.</span><span class="token function">seek</span><span class="token punctuation">(</span>topicPartition<span class="token punctuation">,</span>
                        offsetAndTimestamp<span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>

        <span class="token comment">// 拉去数据打印</span>
        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumerRecords <span class="token operator">=</span> kafkaConsumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumerRecord <span class="token operator">:</span> consumerRecords<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;consumerRecord: &quot;</span> <span class="token operator">+</span> consumerRecord<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><h5 id="_5-5-6-漏消费和重复消费" tabindex="-1"><a class="header-anchor" href="#_5-5-6-漏消费和重复消费" aria-hidden="true">#</a> 5.5.6 漏消费和重复消费</h5><p><strong>重复消费</strong>：已经消费了数据，但是 offset 没有提交。</p><p><strong>漏消费</strong>：先提交 offset 后消费，有可能会造成数据的漏消费。</p><p>（1）场景1：重复消费。自动提交offset引起。</p><p><img src="`+hn+'" alt="64"></p><p>（2）场景1：漏消费。设置offset为手动提交，当offset被提交时，数据还在内存中未落盘，此时刚好消费者线程被kill掉，那么offset已经提交，但是数据未处理，导致这部分内存中的数据丢失。</p><p><img src="'+vn+'" alt="65"></p><p>思考：怎么能做到既不漏消费也不重复消费呢？详看消费者事务。</p><h4 id="_5-6-生产经验-消费者事务" tabindex="-1"><a class="header-anchor" href="#_5-6-生产经验-消费者事务" aria-hidden="true">#</a> 5.6 生产经验----消费者事务</h4><p>如果想完成Consumer端的精准一次性消费，那么需要Kafka消费端将消费过程和提交offset过程做原子绑定。此时我们需要将Kafka的offset保存到支持事务的自定义介质（比 如MySQL）。这部分知识会在后续项目部分涉及。</p><p><img src="'+yn+'" alt="66"></p><h4 id="_5-7-生产经验-数据积压-消费者如何提高吞吐量" tabindex="-1"><a class="header-anchor" href="#_5-7-生产经验-数据积压-消费者如何提高吞吐量" aria-hidden="true">#</a> 5.7 生产经验----数据积压（消费者如何提高吞吐量）</h4><p><img src="'+qn+`" alt="67"></p><table><thead><tr><th>参数名称</th><th>描述</th></tr></thead><tbody><tr><td>fetch.max.bytes</td><td>默认 Default: 52428800（50 m）。消费者获取服务器端一批<br>消息最大的字节数。如果服务器端一批次的数据大于该值<br>（50m）仍然可以拉取回来这批数据，因此，这不是一个绝<br>对最大值。一批次的大小受 message.max.bytes （broker <br>config）or max.message.bytes （topic config）影响。</td></tr><tr><td>max.poll.records</td><td>一次 poll 拉取数据返回消息的最大条数，默认是 500 条</td></tr></tbody></table><h3 id="六、kafka-eagle监控" tabindex="-1"><a class="header-anchor" href="#六、kafka-eagle监控" aria-hidden="true">#</a> 六、Kafka-Eagle监控</h3><p>Kafka-Eagle 框架可以监控 Kafka 集群的整体运行情况，在生产环境中经常使用。</p><h4 id="_6-1-mysql环境准备" tabindex="-1"><a class="header-anchor" href="#_6-1-mysql环境准备" aria-hidden="true">#</a> 6.1 Mysql环境准备</h4><p>Kafka-Eagle 的安装依赖于 MySQL，MySQL 主要用来存储可视化展示的数据。如果集群中之前安装过 MySQL 可以跨过该步。</p><h4 id="_6-2-kafka环境准备" tabindex="-1"><a class="header-anchor" href="#_6-2-kafka环境准备" aria-hidden="true">#</a> 6.2 Kafka环境准备</h4><ol><li><strong>关闭Kafka集群</strong></li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka<span class="token punctuation">]</span>$ kf<span class="token punctuation">.</span>sh stop
</code></pre></div><ol start="2"><li><strong>修改/opt/module/kafka/bin/kafka-server-start.sh命令中</strong></li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka<span class="token punctuation">]</span>$ vim bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>start<span class="token punctuation">.</span>sh
</code></pre></div><p>修改如下参数值：</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token string">&quot;x$KAFKA_HEAP_OPTS&quot;</span> <span class="token operator">=</span> <span class="token string">&quot;x&quot;</span> <span class="token punctuation">]</span><span class="token punctuation">;</span> then
export <span class="token constant">KAFKA_HEAP_OPTS</span><span class="token operator">=</span><span class="token string">&quot;-Xmx1G -Xms1G&quot;</span>
fi
</code></pre></div><p>为</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token string">&quot;x$KAFKA_HEAP_OPTS&quot;</span> <span class="token operator">=</span> <span class="token string">&quot;x&quot;</span> <span class="token punctuation">]</span><span class="token punctuation">;</span> then
export <span class="token constant">KAFKA_HEAP_OPTS</span><span class="token operator">=</span>&quot;<span class="token operator">-</span>server <span class="token operator">-</span><span class="token class-name">Xms2G</span> <span class="token operator">-</span><span class="token class-name">Xmx2G</span> <span class="token operator">-</span>
<span class="token constant">XX</span><span class="token operator">:</span><span class="token class-name">PermSize</span><span class="token operator">=</span><span class="token number">128</span>m <span class="token operator">-</span><span class="token constant">XX</span><span class="token operator">:</span><span class="token operator">+</span><span class="token class-name">UseG1GC</span> <span class="token operator">-</span><span class="token constant">XX</span><span class="token operator">:</span><span class="token class-name">MaxGCPauseMillis</span><span class="token operator">=</span><span class="token number">200</span> <span class="token operator">-</span>
<span class="token constant">XX</span><span class="token operator">:</span><span class="token class-name">ParallelGCThreads</span><span class="token operator">=</span><span class="token number">8</span> <span class="token operator">-</span><span class="token constant">XX</span><span class="token operator">:</span><span class="token class-name">ConcGCThreads</span><span class="token operator">=</span><span class="token number">5</span> <span class="token operator">-</span>
<span class="token constant">XX</span><span class="token operator">:</span><span class="token class-name">InitiatingHeapOccupancyPercent</span><span class="token operator">=</span><span class="token number">70</span>&quot;
export <span class="token constant">JMX_PORT</span><span class="token operator">=</span><span class="token string">&quot;9999&quot;</span>
#export <span class="token constant">KAFKA_HEAP_OPTS</span><span class="token operator">=</span><span class="token string">&quot;-Xmx1G -Xms1G&quot;</span>
fi
</code></pre></div><p>注意：修改之后在启动 Kafka 之前要分发之其他节点</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> bin<span class="token punctuation">]</span>$ xsync kafka<span class="token operator">-</span>server<span class="token operator">-</span>start<span class="token punctuation">.</span>sh
</code></pre></div><h4 id="_6-3-kafka-eagle-安装" tabindex="-1"><a class="header-anchor" href="#_6-3-kafka-eagle-安装" aria-hidden="true">#</a> 6.3 Kafka-Eagle 安装</h4>`,657),Rn={href:"https://www.kafka-eagle.org/",target:"_blank",rel:"noopener noreferrer"},En=n("li",null,[n("p",null,[n("strong",null,"上传压缩包 kafka-eagle-bin-2.0.8.tar.gz 到集群/opt/software目录")])],-1),In=n("li",null,[n("p",null,[n("strong",null,"解压到本地")])],-1),jn=a(`<div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> software<span class="token punctuation">]</span>$ tar <span class="token operator">-</span>zxvf kafka<span class="token operator">-</span>eagle<span class="token operator">-</span>bin<span class="token operator">-</span><span class="token number">2.0</span><span class="token number">.8</span><span class="token punctuation">.</span>tar<span class="token punctuation">.</span>gz
</code></pre></div><ol start="4"><li><strong>进入刚才解压的目录</strong></li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka<span class="token operator">-</span>eagle<span class="token operator">-</span>bin<span class="token operator">-</span><span class="token number">2.0</span><span class="token number">.8</span><span class="token punctuation">]</span>$ ll
总用量 <span class="token number">79164</span>
<span class="token operator">-</span>rw<span class="token operator">-</span>rw<span class="token operator">-</span>r<span class="token operator">--</span><span class="token punctuation">.</span> <span class="token number">1</span> atguigu atguigu <span class="token number">81062577</span> <span class="token number">10</span> 月 <span class="token number">13</span> <span class="token number">00</span><span class="token operator">:</span><span class="token number">00</span> efak<span class="token operator">-</span>web<span class="token operator">-</span>
<span class="token number">2.0</span><span class="token number">.8</span><span class="token operator">-</span>bin<span class="token punctuation">.</span>tar<span class="token punctuation">.</span>gz
</code></pre></div><ol start="5"><li>修改名称</li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> <span class="token keyword">module</span><span class="token punctuation">]</span>$ mv efak<span class="token operator">-</span>web<span class="token operator">-</span><span class="token number">2.0</span><span class="token number">.8</span><span class="token operator">/</span> efak
</code></pre></div><ol start="6"><li><strong>将efak-web-2.0.8-bin.tar.gz 解压至/opt/module</strong></li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> <span class="token keyword">module</span><span class="token punctuation">]</span>$ mv efak<span class="token operator">-</span>web<span class="token operator">-</span><span class="token number">2.0</span><span class="token number">.8</span><span class="token operator">/</span> efak
</code></pre></div><ol start="7"><li><strong>修改配置文件 /opt/module/efak/conf/system-config.properties</strong></li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 conf<span class="token punctuation">]</span>$ <span class="token function">vim</span> system-config.properties
<span class="token comment">######################################</span>
<span class="token comment"># multi zookeeper &amp; kafka cluster list</span>
<span class="token comment"># Settings prefixed with &#39;kafka.eagle.&#39; will be deprecated, use &#39;efak.&#39; </span>
instead
<span class="token comment">######################################</span>
<span class="token assign-left variable">efak.zk.cluster.alias</span><span class="token operator">=</span>cluster1
<span class="token assign-left variable">cluster1.zk.list</span><span class="token operator">=</span>hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka
<span class="token comment">######################################</span>
<span class="token comment"># zookeeper enable acl</span>
<span class="token comment">######################################</span>
<span class="token assign-left variable">cluster1.zk.acl.enable</span><span class="token operator">=</span>false
<span class="token assign-left variable">cluster1.zk.acl.schema</span><span class="token operator">=</span>digest
<span class="token assign-left variable">cluster1.zk.acl.username</span><span class="token operator">=</span>test
<span class="token assign-left variable">cluster1.zk.acl.password</span><span class="token operator">=</span>test123
<span class="token comment">######################################</span>
<span class="token comment"># broker size online list</span>
<span class="token comment">######################################</span>
<span class="token assign-left variable">cluster1.efak.broker.size</span><span class="token operator">=</span><span class="token number">20</span>
<span class="token comment">######################################</span>
<span class="token comment"># zk client thread limit</span>
<span class="token comment">######################################</span>
<span class="token assign-left variable">kafka.zk.limit.size</span><span class="token operator">=</span><span class="token number">32</span>
<span class="token comment">######################################</span>
<span class="token comment"># EFAK webui port</span>
<span class="token comment">######################################</span>
<span class="token assign-left variable">efak.webui.port</span><span class="token operator">=</span><span class="token number">8048</span>
<span class="token comment">######################################</span>
<span class="token comment"># kafka jmx acl and ssl authenticate</span>
<span class="token comment">######################################</span>
<span class="token assign-left variable">cluster1.efak.jmx.acl</span><span class="token operator">=</span>false
<span class="token assign-left variable">cluster1.efak.jmx.user</span><span class="token operator">=</span>keadmin
<span class="token assign-left variable">cluster1.efak.jmx.password</span><span class="token operator">=</span>keadmin123
<span class="token assign-left variable">cluster1.efak.jmx.ssl</span><span class="token operator">=</span>false
<span class="token assign-left variable">cluster1.efak.jmx.truststore.location</span><span class="token operator">=</span>/data/ssl/certificates/kafka.truststor
e
<span class="token assign-left variable">cluster1.efak.jmx.truststore.password</span><span class="token operator">=</span>ke123456
<span class="token comment">######################################</span>
<span class="token comment"># kafka offset storage</span>
<span class="token comment">######################################</span>
<span class="token comment"># offset 保存在 kafka</span>
<span class="token assign-left variable">cluster1.efak.offset.storage</span><span class="token operator">=</span>kafka
<span class="token comment">######################################</span>
<span class="token comment"># kafka jmx uri</span>
<span class="token comment">######################################</span>
<span class="token assign-left variable">cluster1.efak.jmx.uri</span><span class="token operator">=</span>service:jmx:rmi:///jndi/rmi://%s/jmxrmi
<span class="token comment">######################################</span>
<span class="token comment"># kafka metrics, 15 days by default</span>
<span class="token comment">######################################</span>
<span class="token assign-left variable">efak.metrics.charts</span><span class="token operator">=</span>true
<span class="token assign-left variable">efak.metrics.retain</span><span class="token operator">=</span><span class="token number">15</span>
<span class="token comment">######################################</span>
<span class="token comment"># kafka sql topic records max</span>
<span class="token comment">######################################</span>
<span class="token assign-left variable">efak.sql.topic.records.max</span><span class="token operator">=</span><span class="token number">5000</span>
<span class="token assign-left variable">efak.sql.topic.preview.records.max</span><span class="token operator">=</span><span class="token number">10</span>
<span class="token comment">######################################</span>
<span class="token comment"># delete kafka topic token</span>
<span class="token comment">######################################</span>
<span class="token assign-left variable">efak.topic.token</span><span class="token operator">=</span>keadmin
<span class="token comment">######################################</span>
<span class="token comment"># kafka sasl authenticate</span>
<span class="token comment">######################################</span>
<span class="token assign-left variable">cluster1.efak.sasl.enable</span><span class="token operator">=</span>false
<span class="token assign-left variable">cluster1.efak.sasl.protocol</span><span class="token operator">=</span>SASL_PLAINTEXT
<span class="token assign-left variable">cluster1.efak.sasl.mechanism</span><span class="token operator">=</span>SCRAM-SHA-256
<span class="token assign-left variable">cluster1.efak.sasl.jaas.config</span><span class="token operator">=</span>org.apache.kafka.common.security.scram.ScramL
oginModule required <span class="token assign-left variable">username</span><span class="token operator">=</span><span class="token string">&quot;kafka&quot;</span> <span class="token assign-left variable">password</span><span class="token operator">=</span><span class="token string">&quot;kafka-eagle&quot;</span><span class="token punctuation">;</span>
<span class="token assign-left variable">cluster1.efak.sasl.client.id</span><span class="token operator">=</span>
<span class="token assign-left variable">cluster1.efak.blacklist.topics</span><span class="token operator">=</span>
<span class="token assign-left variable">cluster1.efak.sasl.cgroup.enable</span><span class="token operator">=</span>false
<span class="token assign-left variable">cluster1.efak.sasl.cgroup.topics</span><span class="token operator">=</span>
<span class="token assign-left variable">cluster2.efak.sasl.enable</span><span class="token operator">=</span>false
<span class="token assign-left variable">cluster2.efak.sasl.protocol</span><span class="token operator">=</span>SASL_PLAINTEXT
<span class="token assign-left variable">cluster2.efak.sasl.mechanism</span><span class="token operator">=</span>PLAIN
<span class="token assign-left variable">cluster2.efak.sasl.jaas.config</span><span class="token operator">=</span>org.apache.kafka.common.security.plain.PlainL
oginModule required <span class="token assign-left variable">username</span><span class="token operator">=</span><span class="token string">&quot;kafka&quot;</span> <span class="token assign-left variable">password</span><span class="token operator">=</span><span class="token string">&quot;kafka-eagle&quot;</span><span class="token punctuation">;</span>
<span class="token assign-left variable">cluster2.efak.sasl.client.id</span><span class="token operator">=</span>
<span class="token assign-left variable">cluster2.efak.blacklist.topics</span><span class="token operator">=</span>
<span class="token assign-left variable">cluster2.efak.sasl.cgroup.enable</span><span class="token operator">=</span>false
<span class="token assign-left variable">cluster2.efak.sasl.cgroup.topics</span><span class="token operator">=</span>
<span class="token comment">######################################</span>
<span class="token comment"># kafka ssl authenticate</span>
<span class="token comment">######################################</span>
<span class="token assign-left variable">cluster3.efak.ssl.enable</span><span class="token operator">=</span>false
<span class="token assign-left variable">cluster3.efak.ssl.protocol</span><span class="token operator">=</span>SSL
<span class="token assign-left variable">cluster3.efak.ssl.truststore.location</span><span class="token operator">=</span>
<span class="token assign-left variable">cluster3.efak.ssl.truststore.password</span><span class="token operator">=</span>
<span class="token assign-left variable">cluster3.efak.ssl.keystore.location</span><span class="token operator">=</span>
<span class="token assign-left variable">cluster3.efak.ssl.keystore.password</span><span class="token operator">=</span>
<span class="token assign-left variable">cluster3.efak.ssl.key.password</span><span class="token operator">=</span>
<span class="token assign-left variable">cluster3.efak.ssl.endpoint.identification.algorithm</span><span class="token operator">=</span>https
<span class="token assign-left variable">cluster3.efak.blacklist.topics</span><span class="token operator">=</span>
<span class="token assign-left variable">cluster3.efak.ssl.cgroup.enable</span><span class="token operator">=</span>false
<span class="token assign-left variable">cluster3.efak.ssl.cgroup.topics</span><span class="token operator">=</span>
<span class="token comment">######################################</span>
<span class="token comment"># kafka sqlite jdbc driver address</span>
<span class="token comment">######################################</span>
<span class="token comment"># 配置 mysql 连接</span>
<span class="token assign-left variable">efak.driver</span><span class="token operator">=</span>com.mysql.jdbc.Driver
<span class="token assign-left variable">efak.url</span><span class="token operator">=</span>jdbc:mysql://hadoop102:3306/ke?useUnicode<span class="token operator">=</span>true<span class="token operator">&amp;</span><span class="token assign-left variable">characterEncoding</span><span class="token operator">=</span>UT
F-8<span class="token operator">&amp;</span><span class="token assign-left variable">zeroDateTimeBehavior</span><span class="token operator">=</span>convertToNull
<span class="token assign-left variable">efak.username</span><span class="token operator">=</span>root
<span class="token assign-left variable">efak.password</span><span class="token operator">=</span>000000
<span class="token comment">######################################</span>
<span class="token comment"># kafka mysql jdbc driver address</span>
<span class="token comment">######################################</span>
<span class="token comment">#efak.driver=com.mysql.cj.jdbc.Driver</span>
<span class="token comment">#efak.url=jdbc:mysql://127.0.0.1:3306/ke?useUnicode=true&amp;characterEncoding=U</span>
TF-8<span class="token operator">&amp;</span><span class="token assign-left variable">zeroDateTimeBehavior</span><span class="token operator">=</span>convertToNull
<span class="token comment">#efak.username=root</span>
<span class="token comment">#efak.password=123456</span>
</code></pre></div><ol start="8"><li><strong>添加环境变量</strong></li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 conf<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">vim</span> /etc/profile.d/my_env.sh
<span class="token comment"># kafkaEFAK</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">KE_HOME</span><span class="token operator">=</span>/opt/module/efak
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$KE_HOME</span>/bin
</code></pre></div><p>注意：source /etc/profile</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 conf<span class="token punctuation">]</span>$ <span class="token builtin class-name">source</span> /etc/profile
</code></pre></div><ol start="9"><li><p><strong>启动</strong></p><p>（1）注意：启动之前需要先启动 ZK 以及 KAFKA。</p></li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka<span class="token punctuation">]</span>$ kf<span class="token punctuation">.</span>sh start
</code></pre></div><p>​ （2）启动 efak</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> efak<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>ke<span class="token punctuation">.</span>sh start
<span class="token class-name">Version</span> <span class="token number">2.0</span><span class="token number">.8</span> <span class="token operator">--</span> <span class="token class-name">Copyright</span> <span class="token number">2016</span><span class="token operator">-</span><span class="token number">2021</span>
<span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span>
<span class="token operator">*</span> <span class="token constant">EFAK</span> <span class="token class-name">Service</span> has started success<span class="token punctuation">.</span>
<span class="token operator">*</span> <span class="token class-name">Welcome</span><span class="token punctuation">,</span> <span class="token class-name">Now</span> you can visit &#39;http<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span><span class="token number">192.168</span><span class="token number">.10</span><span class="token number">.102</span><span class="token operator">:</span><span class="token number">8048</span>&#39;
<span class="token operator">*</span> <span class="token class-name">Account</span><span class="token operator">:</span>admin <span class="token punctuation">,</span><span class="token class-name">Password</span><span class="token operator">:</span><span class="token number">123456</span>
<span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span>
<span class="token operator">*</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Usage</span><span class="token punctuation">&gt;</span></span> ke<span class="token punctuation">.</span>sh <span class="token punctuation">[</span>start<span class="token operator">|</span>status<span class="token operator">|</span>stop<span class="token operator">|</span>restart<span class="token operator">|</span>stats<span class="token punctuation">]</span> <span class="token operator">&lt;</span><span class="token operator">/</span><span class="token class-name">Usage</span><span class="token operator">&gt;</span>
<span class="token operator">*</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Usage</span><span class="token punctuation">&gt;</span></span> https<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>www<span class="token punctuation">.</span>kafka<span class="token operator">-</span>eagle<span class="token punctuation">.</span>org<span class="token operator">/</span> <span class="token operator">&lt;</span><span class="token operator">/</span><span class="token class-name">Usage</span><span class="token operator">&gt;</span>
<span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span>
</code></pre></div><p>说明：如果停止 efak，执行命令。</p><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> efak<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>ke<span class="token punctuation">.</span>sh stop
</code></pre></div><h4 id="_6-4-kafka-eagle页面操作" tabindex="-1"><a class="header-anchor" href="#_6-4-kafka-eagle页面操作" aria-hidden="true">#</a> 6.4 Kafka-Eagle页面操作</h4><h5 id="_6-4-1-登录页面查看监控数据" tabindex="-1"><a class="header-anchor" href="#_6-4-1-登录页面查看监控数据" aria-hidden="true">#</a> 6.4.1 登录页面查看监控数据</h5><p>http://192.168.10.102:8048/</p><p><img src="`+_n+'" alt="68"></p><p><img src="'+wn+'" alt="69"></p><p><img src="'+Sn+'" alt="70"></p><h3 id="七、kafka-kraft模式" tabindex="-1"><a class="header-anchor" href="#七、kafka-kraft模式" aria-hidden="true">#</a> 七、Kafka-Kraft模式</h3><h4 id="_7-1-kafka-kraft架构" tabindex="-1"><a class="header-anchor" href="#_7-1-kafka-kraft架构" aria-hidden="true">#</a> 7.1 Kafka-Kraft架构</h4><p><img src="'+Cn+`" alt="71"></p><p>左图为 Kafka 现有架构，元数据在 zookeeper 中，运行时动态选举 controller，由controller 进行 Kafka 集群管理。右图为 kraft 模式架构（实验性），不再依赖 zookeeper 集群，而是用三台 controller 节点代替 zookeeper，元数据保存在 controller 中，由 controller 直接进行 Kafka 集群管理。</p><p>这样做的好处有以下几个：</p><ul><li><p>Kafka 不再依赖外部框架，而是能够独立运行；</p></li><li><p>controller 管理集群时，不再需要从 zookeeper 中先读取数据，集群性能上升；</p></li><li><p>由于不依赖 zookeeper，集群扩展时不再受到 zookeeper 读写能力限制；</p></li><li><p>controller 不再动态选举，而是由配置文件规定。这样我们可以有针对性的加强controller 节点的配置，而不是像以前一样对随机 controller 节点的高负载束手无策。</p></li></ul><h4 id="_7-2-kafka-kraft集群部署" tabindex="-1"><a class="header-anchor" href="#_7-2-kafka-kraft集群部署" aria-hidden="true">#</a> 7.2 Kafka-Kraft集群部署</h4><ol><li><strong>再次解压一份kafka安装包</strong></li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> software<span class="token punctuation">]</span>$ tar <span class="token operator">-</span>zxvf kafka_2<span class="token punctuation">.</span><span class="token number">12</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token number">.0</span><span class="token punctuation">.</span>tgz <span class="token operator">-</span><span class="token class-name">C</span> <span class="token operator">/</span>opt<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>
</code></pre></div><ol start="2"><li><strong>重命名为Kafka2</strong></li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> <span class="token keyword">module</span><span class="token punctuation">]</span>$ mv kafka_2<span class="token punctuation">.</span><span class="token number">12</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token number">.0</span><span class="token operator">/</span> kafka2
</code></pre></div><ol start="3"><li><strong>在 hadoop102 上修改/opt/module/kafka2/config/kraft/server.properties 配置文件</strong></li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 kraft<span class="token punctuation">]</span>$ <span class="token function">vim</span> server.properties
<span class="token comment">#kafka 的角色（controller 相当于主机、broker 节点相当于从机，主机类似 zk 功 能）</span>
<span class="token assign-left variable">process.roles</span><span class="token operator">=</span>broker, controller
<span class="token comment">#节点 ID</span>
<span class="token assign-left variable">node.id</span><span class="token operator">=</span><span class="token number">2</span>
<span class="token comment">#controller 服务协议别名</span>
<span class="token assign-left variable">controller.listener.names</span><span class="token operator">=</span>CONTROLLER
<span class="token comment">#全 Controller 列表</span>
<span class="token assign-left variable">controller.quorum.voters</span><span class="token operator">=</span><span class="token number">2</span>@hadoop102:9093,3@hadoop103:9093,4@hado
op104:9093
<span class="token comment">#不同服务器绑定的端口</span>
<span class="token assign-left variable">listeners</span><span class="token operator">=</span>PLAINTEXT://:9092,CONTROLLER://:9093
<span class="token comment">#broker 服务协议别名</span>
<span class="token assign-left variable">inter.broker.listener.name</span><span class="token operator">=</span>PLAINTEXT
<span class="token comment">#broker 对外暴露的地址</span>
<span class="token assign-left variable">advertised.Listeners</span><span class="token operator">=</span>PLAINTEXT://hadoop102:9092
<span class="token comment">#协议别名到安全协议的映射</span>
<span class="token assign-left variable">listener.security.protocol.map</span><span class="token operator">=</span>CONTROLLER:PLAINTEXT,PLAINTEXT:PLA
INTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
<span class="token comment">#kafka 数据存储目录</span>
<span class="token assign-left variable">log.dirs</span><span class="token operator">=</span>/opt/module/kafka2/data
</code></pre></div><ol start="4"><li><strong>发布kafka2</strong></li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> <span class="token keyword">module</span><span class="token punctuation">]</span>$ xsync kafka2<span class="token operator">/</span>
</code></pre></div><ul><li><p>在 hadoop103 和 hadoop104 上 需 要 对 node.id 相应改变 ， 值 需 要 和controller.quorum.voters 对应。</p></li><li><p>在 hadoop103 和 hadoop104 上需要 根据各自的主机名称，修改相应的advertised.Listeners 地址。</p></li></ul><ol start="5"><li><strong>初始化集群数据目录</strong></li></ol><ul><li>① 首先生成存储目录唯一ID</li></ul><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>storage<span class="token punctuation">.</span>sh random<span class="token operator">-</span>uuid
<span class="token class-name">J7s9e8PPTKOO47PxzI39VA</span>
</code></pre></div><ul><li>② 用该 ID 格式化 kafka 存储目录（三台节点）。</li></ul><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>storage<span class="token punctuation">.</span>sh format <span class="token operator">-</span>t 
<span class="token class-name">J7s9e8PPTKOO47PxzI39VA</span> <span class="token operator">-</span>c 
<span class="token operator">/</span>opt<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>kafka2<span class="token operator">/</span>config<span class="token operator">/</span>kraft<span class="token operator">/</span>server<span class="token punctuation">.</span>properties
<span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop103</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>storage<span class="token punctuation">.</span>sh format <span class="token operator">-</span>t 
<span class="token class-name">J7s9e8PPTKOO47PxzI39VA</span> <span class="token operator">-</span>c 
<span class="token operator">/</span>opt<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>kafka2<span class="token operator">/</span>config<span class="token operator">/</span>kraft<span class="token operator">/</span>server<span class="token punctuation">.</span>properties
<span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop104</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>storage<span class="token punctuation">.</span>sh format <span class="token operator">-</span>t 
<span class="token class-name">J7s9e8PPTKOO47PxzI39VA</span> <span class="token operator">-</span>c 
<span class="token operator">/</span>opt<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>kafka2<span class="token operator">/</span>config<span class="token operator">/</span>kraft<span class="token operator">/</span>server<span class="token punctuation">.</span>properties
</code></pre></div><ol start="6"><li>启动kafka集群</li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>start<span class="token punctuation">.</span>sh <span class="token operator">-</span>daemon 
config<span class="token operator">/</span>kraft<span class="token operator">/</span>server<span class="token punctuation">.</span>properties
<span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop103</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>start<span class="token punctuation">.</span>sh <span class="token operator">-</span>daemon 
config<span class="token operator">/</span>kraft<span class="token operator">/</span>server<span class="token punctuation">.</span>properties
<span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop104</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>start<span class="token punctuation">.</span>sh <span class="token operator">-</span>daemon 
config<span class="token operator">/</span>kraft<span class="token operator">/</span>server<span class="token punctuation">.</span>properties
</code></pre></div><ol start="7"><li>停止kafka集群</li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>stop<span class="token punctuation">.</span>sh
<span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop103</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>stop<span class="token punctuation">.</span>sh
<span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop104</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>stop<span class="token punctuation">.</span>sh
</code></pre></div><h4 id="_7-3-kafka-kraft集群启动停止脚本" tabindex="-1"><a class="header-anchor" href="#_7-3-kafka-kraft集群启动停止脚本" aria-hidden="true">#</a> 7.3 Kafka-kraft集群启动停止脚本</h4><ol><li>在/home/atguigu/bin 目录下创建文件 kf2.sh 脚本文件</li></ol><div class="language-java" data-ext="java"><pre class="language-java"><code><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> bin<span class="token punctuation">]</span>$ vim kf2<span class="token punctuation">.</span>sh
</code></pre></div><p>脚本如下：</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token shebang important">#! /bin/bash</span>
<span class="token keyword">case</span> <span class="token variable">$1</span> <span class="token keyword">in</span>
<span class="token string">&quot;start&quot;</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
<span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> hadoop102 hadoop103 hadoop104
<span class="token keyword">do</span>
<span class="token builtin class-name">echo</span> <span class="token string">&quot; --------启动 <span class="token variable">$i</span> Kafka2-------&quot;</span>
<span class="token function">ssh</span> <span class="token variable">$i</span> <span class="token string">&quot;/opt/module/kafka2/bin/kafka-server-start.sh -
daemon /opt/module/kafka2/config/kraft/server.properties&quot;</span>
<span class="token keyword">done</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token punctuation">;</span>
<span class="token string">&quot;stop&quot;</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
<span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> hadoop102 hadoop103 hadoop104
<span class="token keyword">do</span>
<span class="token builtin class-name">echo</span> <span class="token string">&quot; --------停止 <span class="token variable">$i</span> Kafka2-------&quot;</span>
<span class="token function">ssh</span> <span class="token variable">$i</span> <span class="token string">&quot;/opt/module/kafka2/bin/kafka-server-stop.sh &quot;</span>
<span class="token keyword">done</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token punctuation">;</span>
<span class="token keyword">esac</span>
</code></pre></div><ol start="2"><li>添加执行权限</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> +x kf2.sh
</code></pre></div><ol start="3"><li>启动集群命令</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 ~<span class="token punctuation">]</span>$ kf2.sh start
</code></pre></div><ol start="4"><li>停止集群命令</li></ol><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>atguigu@hadoop102 ~<span class="token punctuation">]</span>$ kf2.sh stop
</code></pre></div><p>https://gitee.com/yooome/golang/tree/main/Kafka详细教程</p>`,62);function An(Ln,Tn){const t=o("ExternalLinkIcon");return e(),c("div",null,[Pn,n("ol",null,[n("li",null,[n("p",null,[n("a",Rn,[l("官网"),u(t)])])]),En,In]),jn])}const Kn=p(xn,[["render",An],["__file","kafka_readme.html.vue"]]);export{Kn as default};
