import{_ as o,p as l,q as e,a1 as p}from"./framework-d81ad7e5.js";const r={},i=p(`<p>需求如下：</p><div class="language-sql" data-ext="sql"><pre class="language-sql"><code><span class="token keyword">start</span> <span class="token keyword">transaction</span><span class="token punctuation">;</span>
<span class="token keyword">update</span> t_user <span class="token keyword">set</span> name <span class="token operator">=</span> <span class="token string">&#39;路人甲Java&#39;</span> <span class="token keyword">where</span> user_id <span class="token operator">=</span> <span class="token number">666</span><span class="token punctuation">;</span>
<span class="token keyword">update</span> t_user <span class="token keyword">set</span> name <span class="token operator">=</span> <span class="token string">&#39;javacode2018&#39;</span> <span class="token keyword">where</span> user_id <span class="token operator">=</span> <span class="token number">888</span><span class="token punctuation">;</span>
<span class="token keyword">commit</span><span class="token punctuation">;</span>
</code></pre></div><p>来看一下处理过程：</p><ol><li>找到user_id=666这条记录所在的页p1，将p1从磁盘加载到内存中</li><li>在内存中对p1中user_id=666这条记录信息进行修改</li><li>找到user_id=888这条记录所在的页p2，将p2从磁盘加载到内存中</li><li>在内存中对p2中user_id=888这条记录信息进行修改</li><li>mysql收到commit指令</li><li>将p1页写入磁盘</li><li>将p2页写入磁盘</li><li>给客户端返回更新成功</li></ol><p>上面过程我们看有什么问题</p><ol><li>假如6成功之后，mysql宕机了，此时p1修改已写入磁盘，但是p2的修改还未写入磁盘，最终导致user_id=666的记录被修改成功了，user_id=888的数据被修改失败了，数据是有问题的</li><li>上面p1和p2可能位于磁盘的不同位置，涉及到磁盘随机写的问题，导致整个过程耗时也比较长</li></ol><p><strong>上面问题可以归纳为2点：无法确保数据可靠性、随机写导致耗时比较长。</strong></p><p>关于上面问题，我们看一下mysql是如何优化的，mysql内部引入了一个redo log，这是一个文件，对于上面2条更新操作，mysql实现如下：</p><blockquote><p>mysql内部有个redo log buffer，是内存中一块区域，我们将其理解为数组结构，向redo log文件中写数据时，会先将内容写入redo log buffer中，后续会将这个buffer中的内容写入磁盘中的redo log文件，这个个redo log buffer是整个mysql中所有连接共享的内存区域，可以被重复使用。</p></blockquote><ol><li><p>mysql收到start transaction后，生成一个全局的事务编号trx_id，比如trx_id=10</p></li><li><p>user_id=666这个记录我们就叫r1，user_id=888这个记录叫r2</p></li><li><p>找到r1记录所在的数据页p1，将其从磁盘中加载到内存中</p></li><li><p>在内存中找到r1在p1中的位置，然后对p1进行修改（这个过程可以描述为：将p1中的pos_start1到pos_start2位置的值改为v1），这个过程我们记为rb1(内部包含事务编号trx_id)，将rb1放入redo log buffer数组中，此时p1的信息在内存中被修改了，和磁盘中p1的数据不一样了</p></li><li><p>找到r2记录所在的数据页p2，将其从磁盘中加载到内存中</p></li><li><p>在内存中找到r2在p2中的位置，然后对p2进行修改（这个过程可以描述为：将p2中的pos_start1到pos_start2位置的值改为v2），这个过程我们记为rb2(内部包含事务编号trx_id)，将rb2放入redo log buffer数组中，此时p2的信息在内存中被修改了，和磁盘中p2的数据不一样了</p></li><li><p>此时redo log buffer数组中有2条记录[rb1,rb2]</p></li><li><p>mysql收到commit指令</p></li><li><p>将redo log buffer数组中内容写入到redo log文件中，写入的内容：</p></li></ol><div class="language-text" data-ext="text"><pre class="language-text"><code>1.start trx=10;
2.写入rb1
3.写入rb2
4.end trx=10;
</code></pre></div><ol start="10"><li>返回给客户端更新成功。</li></ol><p>上面过程执行完毕之后，数据是这样的：</p><ol><li>内存中p1、p2页被修改了，还未同步到磁盘中，此时内存中数据页和磁盘中数据页是不一致的，此时内存中数据页我们称为脏页</li><li>对p1、p2页修改被持久到磁盘中的redolog文件中了，不会丢失</li></ol><p>认真看一下上面过程中第9步骤，一个成功的事务记录在redo log中是有start和end的，redo log文件中如果一个trx_id对应start和end成对出现，说明这个事务执行成功了，如果只有start没有end说明是有问题的。</p><p><strong>那么对p1、p2页的修改什么时候会同步到磁盘中呢？</strong></p><p>redo log是mysql中所有连接共享的文件，对mysql执行insert、delete和上面update的过程类似，都是先在内存中修改页数据，然后将修改过程持久化到redo log所在的磁盘文件中，然后返回成功。redo log文件是有大小的，需要重复利用的（redo log有多个，多个之间采用环形结构结合几个变量来做到重复利用，这块知识不做说明，有兴趣的可以去网上找一下），<strong>当redo log满了，或者系统比较闲的时候</strong>，会对redo log文件中的内容进行处理，处理过程如下：</p><ol><li>读取redo log信息，读取一个完整的trx_id对应的信息，然后进行处理</li><li>比如读取到了trx_id=10的完整内容，包含了start end，表示这个事务操作是成功的，然后继续向下</li><li>判断p1在内存中是否存在，如果存在，则直接将p1信息写到p1所在的磁盘中；如果p1在内存中不存在，则将p1从磁盘加载到内存，通过redo log中的信息在内存中对p1进行修改，然后将其写到磁盘中</li></ol><p>上面的update之后，p1在内存中是存在的，并且p1是已经被修改过的，可以直接刷新到磁盘中。</p><p>如果上面的update之后，mysql宕机，然后重启了，p1在内存中是不存在的，此时系统会读取redo log文件中的内容进行恢复处理。</p><ol start="4"><li><p>将redo log文件中trx_id=10的占有的空间标记为已处理，这块空间会被释放出来可以重复利用了</p></li><li><p>如果第2步读取到的trx_id对应的内容没有end，表示这个事务执行到一半失败了（可能是第9步骤写到一半宕机了），此时这个记录是无效的，可以直接跳过不用处理</p></li></ol><p>上面的过程做到了：数据最后一定会被持久化到磁盘中的页中，不会丢失，做到了可靠性。</p><p>并且内部采用了先把页的修改操作先在内存中进行操作，然后再写入了redo log文件，此处redo log是按顺序写的，使用到了io的顺序写，效率会非常高，相对于用户来说响应会更快。</p><p>对于将数据页的变更持久化到磁盘中，此处又采用了异步的方式去读取redo log的内容，然后将页的变更刷到磁盘中，这块的设计也非常好，异步刷盘操作！</p><p>但是有一种情况，当一个事务commit的时候，刚好发现redo log不够了，此时会先停下来处理redo log中的内容，然后在进行后续的操作，遇到这种情况时，整个事物响应会稍微慢一些。</p><h2 id="binlog" tabindex="-1"><a class="header-anchor" href="#binlog" aria-hidden="true">#</a> binlog</h2><p>mysql中还有一个binlog，在事务操作过程中也会写binlog，先说一下binlog的作用，binlog中详细记录了对数据库做了什么操作，算是对数据库操作的一个流水，这个流水也是相当重要的，主从同步就是使用binlog来实现的，从库读取主库中binlog的信息，然后在从库中执行，最后，从库就和主库信息保持同步一致了。还有一些其他系统也可以使用binlog的功能，比如可以通过binlog来实现bi系统中etl的功能，将业务数据抽取到数据仓库，<strong>阿里提供了一个java版本的项目：canal</strong>，这个项目可以模拟从库从主库读取binlog的功能，也就是说可以通过java程序来监控数据库详细变化的流水，这个大家可以脑洞大开一下，可以做很多事情的，有兴趣的朋友可以去研究一下；所以binlog对mysql来说也是相当重要的</p><h4 id="看一下系统如何确保redo-log-和binlog在一致性的-都写入成功的。" tabindex="-1"><a class="header-anchor" href="#看一下系统如何确保redo-log-和binlog在一致性的-都写入成功的。" aria-hidden="true">#</a> 看一下系统如何确保redo log 和binlog在一致性的，都写入成功的。</h4><p>还是以update为例：</p><div class="language-text" data-ext="text"><pre class="language-text"><code>start transaction;
update t_user set name = &#39;路人甲Java&#39; where user_id = 666;
update t_user set name = &#39;javacode2018&#39; where user_id = 888;
commit;
</code></pre></div><blockquote><p>一个事务中可能有很多操作，这些操作会写很多binlog日志，为了加快写的速度，mysql先把整个过程中产生的binlog日志先写到内存中的binlog cache缓存中，后面再将binlog cache中内容一次性持久化到binlog文件中。</p></blockquote><p>过程如下：</p><ol><li><p>mysql收到start transaction后，生成一个全局的事务编号trx_id，比如trx_id=10</p></li><li><p>user_id=666这个记录我们就叫r1，user_id=888这个记录叫r2</p></li><li><p>找到r1记录所在的数据页p1，将其从磁盘中加载到内存中</p></li><li><p>在内存中对p1进行修改</p></li><li><p>将p1修改操作记录到redo log buffer中</p></li><li><p>将p1修改记录流水记录到binlog cache中</p></li><li><p>找到r2记录所在的数据页p2，将其从磁盘中加载到内存中</p></li><li><p>在内存中对p2进行修改</p></li><li><p>将p2修改操作记录到redo log buffer中</p></li><li><p>将p2修改记录流水记录到binlog cache中</p></li><li><p>mysql收到commit指令</p></li><li><p>将redo log buffer携带trx_id=10写入到redo log文件，持久化到磁盘，<strong>这步操作叫做redo log prepare</strong>，内容如下</p><blockquote><p>1.start trx=10; 2.写入rb1 3.写入rb2 4.prepare trx=10;</p><p><strong>注意上面是prepare了，不是之前说的end了。</strong></p></blockquote></li><li><p>将binlog cache携带trx_id=10写入到binlog文件，持久化到磁盘</p></li><li><p>向redo log中写入一条数据：<code>end trx=10;</code>表示redo log中这个事务完成了，<strong>这步操作叫做redo log commit</strong></p></li><li><p>返回给客户端更新成功</p></li></ol><p>我们来分析一下上面过程可能出现的一些情况：</p><p>步骤10操作完成后，mysql宕机了</p><blockquote><p>宕机之前，所有修改都位于内存中，mysql重启之后，内存修改还未同步到磁盘，对磁盘数据没有影响，所以无影响。</p></blockquote><p>步骤12执行完毕之后，mysql宕机了</p><blockquote><p>此时redo log prepare过程是写入redo log文件了，但是binlog写入失败了，此时mysql重启之后会读取redo log进行恢复处理，查询到trx_id=10的记录是prepare状态，会去binlog中查找trx_id=10的操作在binlog中是否存在，如果不存在，说明binlog写入失败了，此时可以将此操作回滚</p></blockquote><p>步骤13执行完毕之后，mysql宕机</p><blockquote><p>此时redo log prepare过程是写入redo log文件了，但是binlog写入失败了，此时mysql重启之后会读取redo log进行恢复处理，查询到trx_id=10的记录是prepare状态，会去binlog中查找trx_id=10的操作在binlog是存在的，然后接着执行上面的步骤14和15.</p></blockquote><h4 id="做一个总结" tabindex="-1"><a class="header-anchor" href="#做一个总结" aria-hidden="true">#</a> 做一个总结</h4><p>上面的过程设计比较好的地方，有2点</p><p><strong>日志先行，io顺序写，异步操作，做到了高效操作</strong></p><blockquote><p>对数据页，先在内存中修改，然后使用io顺序写的方式持久化到redo log文件；然后异步去处理redo log，将数据页的修改持久化到磁盘中，效率非常高，整个过程，其实就是 MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。</p></blockquote><p><strong>两阶段提交确保redo log和binlog一致性</strong></p><blockquote><p>为了确保redo log和binlog一致性，此处使用了二阶段提交技术，redo log 和binlog的写分了3步走：</p><ol><li>携带trx_id，redo log prepare到磁盘</li><li>携带trx_id，binlog写入磁盘</li><li>携带trx_id，redo log commit到磁盘</li></ol><p>上面3步骤，可以确保同一个trx_id关联的redo log 和binlog的可靠性。</p></blockquote><p>关于上面2点优秀的设计</p>`,47),s=[i];function t(a,n){return l(),e("div",null,s)}const g=o(r,[["render",t],["__file","msq_a_redo.html.vue"]]);export{g as default};
